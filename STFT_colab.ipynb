{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1QABfSWGOb60Usmj_mvb2SPfbqfqsz8I0","authorship_tag":"ABX9TyNmbuTxmqZolSzPEpLxuOCn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# !pip install -q condacolab\n","# import condacolab\n","# condacolab.install()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gofGmAev0-AY","executionInfo":{"status":"ok","timestamp":1675806162991,"user_tz":-60,"elapsed":28574,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"71d726de-f475-430b-d277-e0a3cea8af85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n","ðŸ“¦ Installing...\n","ðŸ“Œ Adjusting configuration...\n","ðŸ©¹ Patching environment...\n","â² Done in 0:00:20\n","ðŸ” Restarting kernel...\n"]}]},{"cell_type":"code","source":["# import condacolab\n","# condacolab.check()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1KgwZTTS1PSR","executionInfo":{"status":"ok","timestamp":1675806179167,"user_tz":-60,"elapsed":236,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"50340263-3ff4-4e2f-cb52-0c67ee3bdc5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ¨ðŸ°âœ¨ Everything looks OK!\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","import os\n","ROOT_DIR = \"/content/drive/My Drive/\"\n","os.chdir(os.path.join(ROOT_DIR, \"Master/Python/\"))"],"metadata":{"id":"1R6r_SbjP7mY","executionInfo":{"status":"ok","timestamp":1676125771807,"user_tz":-60,"elapsed":5,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%ls\n","%cd /content/\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bzqd1VvwQrTN","executionInfo":{"status":"ok","timestamp":1676125774823,"user_tz":-60,"elapsed":767,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"fd8addfe-636f-41b1-99b8-2fc08be43b65"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/  STFT.ipynb\n","/content\n","\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["# !pip list"],"metadata":{"id":"VpE79wOmBZKN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch==1.4.0 torchvision==0.5.0\n","# !pip install torch==1.5.0 torchvision==0.6.0\n","# !pip install torch==1.6.0 torchvision==0.7.0"],"metadata":{"id":"EaecdXQRBLRz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676125836205,"user_tz":-60,"elapsed":61387,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"39180d5d-1077-4f05-8b21-6d67372c4988"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp38-cp38-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m753.4/753.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.5.0\n","  Downloading torchvision-0.5.0-cp38-cp38-manylinux1_x86_64.whl (4.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.5.0) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.5.0) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchvision==0.5.0) (1.15.0)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.1+cu116\n","    Uninstalling torchvision-0.14.1+cu116:\n","      Successfully uninstalled torchvision-0.14.1+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n","fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n","fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.4.0 torchvision-0.5.0\n"]}]},{"cell_type":"code","source":["# !conda --version    \n","# !which python\n","# !python --version\n","# !echo $PYTHONPATH\n","# %env PYTHONPATH=\n","# !echo $PYTHONPATH   "],"metadata":{"id":"D8yQpjvhoCKC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ################################################################################\n","# # INSTALL CONDA ON GOOGLE COLAB\n","# ################################################################################\n","# ! wget https://repo.anaconda.com/miniconda/Miniconda3-py38_22.11.1-1-Linux-x86_64.sh\n","# ! chmod +x Miniconda3-p38_22.11.1-1-Linux-x86_64.sh\n","# ! bash ./Miniconda3-py38_22.11.1-1-Linux-x86_64.sh -b -f -p /usr/local/\n","     \n"],"metadata":{"id":"qit7EkyqqiYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !which conda\n","# !conda --version"],"metadata":{"id":"UHe-esRCq36R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda install --channel defaults conda python=3.8 --yes\n","# !conda update --channel defaults --all --yes    "],"metadata":{"id":"b5jjt_ztURkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !which conda\n","# !conda --version"],"metadata":{"id":"vX4efTEHscy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import sys\n","# sys.path.append(\"/usr/local/lib/python3.8/site-packages\")"],"metadata":{"id":"vM1mFka1s4Vj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda config --add channels bioconda\n","\n","# !conda config --add channels conda-forge"],"metadata":{"id":"EEMRusq_tDdN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda env list"],"metadata":{"id":"rDAbFHlAtLr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # create a conda virtual environment\n","# !conda create --name STFT -y python=3.7\n","# !conda activate STFT"],"metadata":{"id":"XnkyWb4QtSXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda init bash"],"metadata":{"id":"gSW9Yb24vQrF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !cat /root/.bashrc"],"metadata":{"id":"X0YXeQlXvhUG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda activate STFT\n","# !conda info --envs"],"metadata":{"id":"C4cEcx45uln2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install the right pip and dependencies\n","# !conda install -y ipython pip\n","# !pip install ninja yacs cython matplotlib tqdm opencv-python scipy"],"metadata":{"id":"AheS1fS619_Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda list"],"metadata":{"id":"Tt1j9QOi2t4o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !nvidia-smi"],"metadata":{"id":"4_35qgF13G1l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !conda config --remove channels conda-forge\n","# !conda config --add channels conda-forge\n","# !conda update conda"],"metadata":{"id":"uGSrR7tsoCpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # PyTorch installation with CUDA 11.6\n","# # !conda install pytorch torchvision pytorch-cuda=11.6 -c pytorch -c nvidia\n","# !conda install -y pytorch torchvision cudatoolkit=11.6 -c pytorch"],"metadata":{"id":"KZmxruix28bN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"eW7HvTA7NKH0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676125843671,"user_tz":-60,"elapsed":7474,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"fac7107e-4a07-4d38-f409-f51806031a85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yacs\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (0.29.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Installing collected packages: ninja, yacs\n","Successfully installed ninja-1.11.1 yacs-0.1.8\n"]}],"source":["%pip install ninja yacs cython matplotlib tqdm opencv-python scipy"]},{"cell_type":"code","source":["# install pycocotools\n","!git clone https://github.com/cocodataset/cocoapi.git\n","%cd cocoapi/PythonAPI\n","!python setup.py build_ext install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-rth9W2T9-V","executionInfo":{"status":"ok","timestamp":1676125852995,"user_tz":-60,"elapsed":9338,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"5d2248a8-490f-4ca5-f424-195e5708c7ea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 25.49 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n","/content/cocoapi/PythonAPI\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.8\n","creating build/temp.linux-x86_64-3.8/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I../common -I/usr/include/python3.8 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.8/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[KrleDecode\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™\n","   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™\n","  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kfor\u001b[m\u001b[Kâ€™\n","  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[KrleToString\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kif\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kif\u001b[m\u001b[Kâ€™\n","  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[KrleFrString\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kwhile\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kwhile\u001b[m\u001b[Kâ€™\n","  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis â€˜\u001b[01m\u001b[Kif\u001b[m\u001b[Kâ€™ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the â€˜\u001b[01m\u001b[Kif\u001b[m\u001b[Kâ€™\n","  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I../common -I/usr/include/python3.8 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.8/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.8\n","creating build/lib.linux-x86_64-3.8/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/../common/maskApi.o build/temp.linux-x86_64-3.8/pycocotools/_mask.o -o build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so\n","running install\n","running bdist_egg\n","running egg_info\n","creating pycocotools.egg-info\n","writing pycocotools.egg-info/PKG-INFO\n","writing dependency_links to pycocotools.egg-info/dependency_links.txt\n","writing requirements to pycocotools.egg-info/requires.txt\n","writing top-level names to pycocotools.egg-info/top_level.txt\n","writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n","reading manifest file 'pycocotools.egg-info/SOURCES.txt'\n","writing manifest file 'pycocotools.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","copying pycocotools/mask.py -> build/lib.linux-x86_64-3.8/pycocotools\n","copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-3.8/pycocotools\n","copying pycocotools/coco.py -> build/lib.linux-x86_64-3.8/pycocotools\n","copying pycocotools/__init__.py -> build/lib.linux-x86_64-3.8/pycocotools\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/pycocotools\n","copying build/lib.linux-x86_64-3.8/pycocotools/mask.py -> build/bdist.linux-x86_64/egg/pycocotools\n","copying build/lib.linux-x86_64-3.8/pycocotools/cocoeval.py -> build/bdist.linux-x86_64/egg/pycocotools\n","copying build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/pycocotools\n","copying build/lib.linux-x86_64-3.8/pycocotools/coco.py -> build/bdist.linux-x86_64/egg/pycocotools\n","copying build/lib.linux-x86_64-3.8/pycocotools/__init__.py -> build/bdist.linux-x86_64/egg/pycocotools\n","byte-compiling build/bdist.linux-x86_64/egg/pycocotools/mask.py to mask.cpython-38.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/pycocotools/cocoeval.py to cocoeval.cpython-38.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/pycocotools/coco.py to coco.cpython-38.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/pycocotools/__init__.py to __init__.cpython-38.pyc\n","creating stub loader for pycocotools/_mask.cpython-38-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/pycocotools/_mask.py to _mask.cpython-38.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying pycocotools.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying pycocotools.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying pycocotools.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying pycocotools.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying pycocotools.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","zip_safe flag not set; analyzing archive contents...\n","pycocotools.__pycache__._mask.cpython-38: module references __file__\n","creating dist\n","creating 'dist/pycocotools-2.0-py3.8-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing pycocotools-2.0-py3.8-linux-x86_64.egg\n","creating /usr/local/lib/python3.8/dist-packages/pycocotools-2.0-py3.8-linux-x86_64.egg\n","Extracting pycocotools-2.0-py3.8-linux-x86_64.egg to /usr/local/lib/python3.8/dist-packages\n","Adding pycocotools 2.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.8/dist-packages/pycocotools-2.0-py3.8-linux-x86_64.egg\n","Processing dependencies for pycocotools==2.0\n","Searching for matplotlib==3.2.2\n","Best match: matplotlib 3.2.2\n","Adding matplotlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for Cython==0.29.33\n","Best match: Cython 0.29.33\n","Adding Cython 0.29.33 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for setuptools==57.4.0\n","Best match: setuptools 57.4.0\n","Adding setuptools 57.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for pyparsing==3.0.9\n","Best match: pyparsing 3.0.9\n","Adding pyparsing 3.0.9 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for cycler==0.11.0\n","Best match: cycler 0.11.0\n","Adding cycler 0.11.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for python-dateutil==2.8.2\n","Best match: python-dateutil 2.8.2\n","Adding python-dateutil 2.8.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for numpy==1.21.6\n","Best match: numpy 1.21.6\n","Adding numpy 1.21.6 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.8 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for kiwisolver==1.4.4\n","Best match: kiwisolver 1.4.4\n","Adding kiwisolver 1.4.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.8/dist-packages\n","Finished processing dependencies for pycocotools==2.0\n"]}]},{"cell_type":"code","source":["!rm -r /content/STFT/"],"metadata":{"id":"Si8znXdBJjK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install STFT\n","%cd /content/\n","!git clone https://github.com/Lechtr/STFT.git\n","%cd STFT\n","# !python setup.py build develop"],"metadata":{"id":"-gsHne4-my3W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676125868615,"user_tz":-60,"elapsed":9451,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"ac7ca70c-b961-46df-a4c5-53fb935aa0c5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'STFT'...\n","remote: Enumerating objects: 748, done.\u001b[K\n","remote: Counting objects: 100% (71/71), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 748 (delta 24), reused 43 (delta 18), pack-reused 677\u001b[K\n","Receiving objects: 100% (748/748), 95.83 MiB | 15.60 MiB/s, done.\n","Resolving deltas: 100% (239/239), done.\n","Updating files: 100% (222/222), done.\n","/content/STFT\n"]}]},{"cell_type":"code","source":["# !git checkout torch1.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjVBJ_tZJUjj","executionInfo":{"status":"ok","timestamp":1675981047602,"user_tz":-60,"elapsed":741,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"12110582-4f8e-480d-9718-f853fae352a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Branch 'torch1.5' set up to track remote branch 'torch1.5' from 'origin'.\n","Switched to a new branch 'torch1.5'\n"]}]},{"cell_type":"code","source":["!python setup.py build develop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vnbp1STHxxT","executionInfo":{"status":"ok","timestamp":1676126125744,"user_tz":-60,"elapsed":247689,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"4f17748b-b990-484f-cc27-2a08c3fdaf96"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["running build\n","running build_py\n","creating build\n","creating build/lib.linux-x86_64-3.8\n","creating build/lib.linux-x86_64-3.8/stft_core\n","copying stft_core/__init__.py -> build/lib.linux-x86_64-3.8/stft_core\n","creating build/lib.linux-x86_64-3.8/stft_core/data\n","copying stft_core/data/build.py -> build/lib.linux-x86_64-3.8/stft_core/data\n","copying stft_core/data/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data\n","copying stft_core/data/collate_batch.py -> build/lib.linux-x86_64-3.8/stft_core/data\n","creating build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/boxlist_ops.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/segmentation_mask.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/image_list.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/keypoint.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","copying stft_core/structures/bounding_box.py -> build/lib.linux-x86_64-3.8/stft_core/structures\n","creating build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/collect_env.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/cv2_util.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/c2_model_loading.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/philly_env.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/metric_logger.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/logger.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/model_serialization.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/imports.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/env.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/comm.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/registry.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/miscellaneous.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/checkpoint.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/model_zoo.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/timer.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/distributed.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","copying stft_core/utils/dist_env.py -> build/lib.linux-x86_64-3.8/stft_core/utils\n","creating build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/iou_loss.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/sigmoid_focal_loss.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/scale.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/roi_pool.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/border_align.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/roi_align.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/context_block.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/batch_norm.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/nms.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/ctdet_loss.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/smooth_l1_loss.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/_utils.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","copying stft_core/layers/misc.py -> build/lib.linux-x86_64-3.8/stft_core/layers\n","creating build/lib.linux-x86_64-3.8/stft_core/solver\n","copying stft_core/solver/lr_scheduler.py -> build/lib.linux-x86_64-3.8/stft_core/solver\n","copying stft_core/solver/build.py -> build/lib.linux-x86_64-3.8/stft_core/solver\n","copying stft_core/solver/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/solver\n","creating build/lib.linux-x86_64-3.8/stft_core/config\n","copying stft_core/config/defaults.py -> build/lib.linux-x86_64-3.8/stft_core/config\n","copying stft_core/config/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/config\n","copying stft_core/config/paths_catalog.py -> build/lib.linux-x86_64-3.8/stft_core/config\n","creating build/lib.linux-x86_64-3.8/stft_core/engine\n","copying stft_core/engine/bbox_aug.py -> build/lib.linux-x86_64-3.8/stft_core/engine\n","copying stft_core/engine/inference.py -> build/lib.linux-x86_64-3.8/stft_core/engine\n","copying stft_core/engine/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/engine\n","copying stft_core/engine/trainer.py -> build/lib.linux-x86_64-3.8/stft_core/engine\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/registry.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/box_coder.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/make_layers.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/matcher.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/balanced_positive_negative_sampler.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/poolers.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","copying stft_core/modeling/utils.py -> build/lib.linux-x86_64-3.8/stft_core/modeling\n","creating build/lib.linux-x86_64-3.8/stft_core/data/samplers\n","copying stft_core/data/samplers/grouped_batch_sampler.py -> build/lib.linux-x86_64-3.8/stft_core/data/samplers\n","copying stft_core/data/samplers/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/samplers\n","copying stft_core/data/samplers/iteration_based_batch_sampler.py -> build/lib.linux-x86_64-3.8/stft_core/data/samplers\n","copying stft_core/data/samplers/distributed.py -> build/lib.linux-x86_64-3.8/stft_core/data/samplers\n","creating build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/vid_fgfa.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/cvcvid_rdn.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/vid_rdn.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/cvcvid_image.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/vid.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/list_dataset.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/cvcvid_stft.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/vid_stft.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/cvcvid_fgfa.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/concat_dataset.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/cvcvid_mega.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","copying stft_core/data/datasets/vid_mega.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets\n","creating build/lib.linux-x86_64-3.8/stft_core/data/transforms\n","copying stft_core/data/transforms/transforms.py -> build/lib.linux-x86_64-3.8/stft_core/data/transforms\n","copying stft_core/data/transforms/build.py -> build/lib.linux-x86_64-3.8/stft_core/data/transforms\n","copying stft_core/data/transforms/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/transforms\n","creating build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation\n","copying stft_core/data/datasets/evaluation/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation\n","creating build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/cvcvid\n","copying stft_core/data/datasets/evaluation/cvcvid/cvcvideo_eval.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/cvcvid\n","copying stft_core/data/datasets/evaluation/cvcvid/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/cvcvid\n","creating build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/vid\n","copying stft_core/data/datasets/evaluation/vid/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/vid\n","copying stft_core/data/datasets/evaluation/vid/vid_eval.py -> build/lib.linux-x86_64-3.8/stft_core/data/datasets/evaluation/vid\n","creating build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","copying stft_core/layers/dcn/deform_conv_func.py -> build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","copying stft_core/layers/dcn/deform_conv_module.py -> build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","copying stft_core/layers/dcn/deform_pool_func.py -> build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","copying stft_core/layers/dcn/deform_pool_module.py -> build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","copying stft_core/layers/dcn/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/layers/dcn\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/flownet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/fpn.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/resnet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/fbnet_builder.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/embednet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/fbnet_modeldef.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/backbone.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/fbnet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","copying stft_core/modeling/backbone/resnet_dcn.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/backbone\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/generalized_rcnn_mega.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/generalized_rcnn_fgfa.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/generalized_rcnn_stft.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/detectors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/generalized_rcnn.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","copying stft_core/modeling/detector/generalized_rcnn_rdn.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/detector\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads\n","copying stft_core/modeling/roi_heads/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads\n","copying stft_core/modeling/roi_heads/ctdet_heads.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads\n","copying stft_core/modeling/roi_heads/roi_heads.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/anchor_generator.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/rpn.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","copying stft_core/modeling/rpn/utils.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/roi_box_feature_extractors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/box_head.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","copying stft_core/modeling/roi_heads/box_head/roi_box_predictors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/box_head\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/roi_mask_predictors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/mask_head.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","copying stft_core/modeling/roi_heads/mask_head/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/mask_head\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/keypoint_head.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/roi_keypoint_predictors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","copying stft_core/modeling/roi_heads/keypoint_head/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/roi_heads/keypoint_head\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/retinanet\n","copying stft_core/modeling/rpn/retinanet/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/retinanet\n","copying stft_core/modeling/rpn/retinanet/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/retinanet\n","copying stft_core/modeling/rpn/retinanet/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/retinanet\n","copying stft_core/modeling/rpn/retinanet/retinanet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/retinanet\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos\n","copying stft_core/modeling/rpn/fcos/fcos.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos\n","copying stft_core/modeling/rpn/fcos/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos\n","copying stft_core/modeling/rpn/fcos/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos\n","copying stft_core/modeling/rpn/fcos/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos_stft\n","copying stft_core/modeling/rpn/fcos_stft/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos_stft\n","copying stft_core/modeling/rpn/fcos_stft/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos_stft\n","copying stft_core/modeling/rpn/fcos_stft/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos_stft\n","copying stft_core/modeling/rpn/fcos_stft/fcos_stft.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/fcos_stft\n","creating build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/borderdet\n","copying stft_core/modeling/rpn/borderdet/borderdet.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/borderdet\n","copying stft_core/modeling/rpn/borderdet/loss.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/borderdet\n","copying stft_core/modeling/rpn/borderdet/inference.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/borderdet\n","copying stft_core/modeling/rpn/borderdet/__init__.py -> build/lib.linux-x86_64-3.8/stft_core/modeling/rpn/borderdet\n","running build_ext\n","building 'stft_core._C' extension\n","creating build/temp.linux-x86_64-3.8\n","creating build/temp.linux-x86_64-3.8/content\n","creating build/temp.linux-x86_64-3.8/content/STFT\n","creating build/temp.linux-x86_64-3.8/content/STFT/stft_core\n","creating build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc\n","creating build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cpu\n","creating build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/vision.cpp -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/vision.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  103 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n","      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   31 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n","      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  103 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n","      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   31 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n","      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:245:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  245 |          input.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n","      |                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:253:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  253 |          rois.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n","      |                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:254:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  254 |          output.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K);\n","      |                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:245:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  245 |          input.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n","      |                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:253:30:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  253 |          rois.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K,\n","      |                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:254:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  254 |          output.data<scalar_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K);\n","      |                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:12:12:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KAT_PRIVATE_CASE_TYPE\u001b[m\u001b[Kâ€™\n","   12 |     return \u001b[01;36m\u001b[K__VA_ARGS__\u001b[m\u001b[K();                          \\\n","      |            \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:242:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","  242 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(input.type(), \"ROIAlign_forward\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:\u001b[m\u001b[K In lambda function:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  103 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n","      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","   71 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   31 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n","      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:103:56:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","  103 |     at::ScalarType _st = ::detail::scalar_type(the_type\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                    \\\n","      |                                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[Kâ€™\n","   71 |   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n","      |   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Dispatch.h:31:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   31 | inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n","      |                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n","/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp: In instantiation of â€˜\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = double]\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K   required from here\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:29:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   29 |   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n","      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:30:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   30 |   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n","      |                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   31 |   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   32 |   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:33:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   33 |   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:34:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   34 |   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:35:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   35 |   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp: In instantiation of â€˜\u001b[01m\u001b[Kat::Tensor nms_cpu_kernel(const at::Tensor&, const at::Tensor&, float) [with scalar_t = float]\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:71:3:\u001b[m\u001b[K   required from here\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:29:47:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   29 |   auto suppressed = \u001b[01;35m\u001b[Ksuppressed_t.data<uint8_t>()\u001b[m\u001b[K;\n","      |                     \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:30:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   30 |   auto order = \u001b[01;35m\u001b[Korder_t.data<int64_t>()\u001b[m\u001b[K;\n","      |                \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:31:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   31 |   auto \u001b[01;35m\u001b[Kx1\u001b[m\u001b[K = x1_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:32:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   32 |   auto \u001b[01;35m\u001b[Ky1\u001b[m\u001b[K = y1_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:33:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   33 |   auto \u001b[01;35m\u001b[Kx2\u001b[m\u001b[K = x2_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:34:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   34 |   auto \u001b[01;35m\u001b[Ky2\u001b[m\u001b[K = y2_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:35:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   35 |   auto \u001b[01;35m\u001b[Kareas\u001b[m\u001b[K = areas_t.data<scalar_t>();\n","      |        \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:11\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/ATen.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/vision.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/STFT/stft_core/csrc/cpu/nms_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:322:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","  322 |   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","      |       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/SigmoidFocalLoss_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/SigmoidFocalLoss_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/ROIPool_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/ROIPool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/deform_pool_kernel_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_pool_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/deform_conv_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_conv_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/BorderAlign_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/BorderAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/nms.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/nms.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/ROIAlign_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/ROIAlign_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/deform_conv_kernel_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_conv_kernel_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/STFT/stft_core/csrc -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.8 -c /content/STFT/stft_core/csrc/cuda/deform_pool_cuda.cu -o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_pool_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","\u001b[01m\u001b[0m\u001b[01m/usr/local/lib/python3.8/dist-packages/torch/include/c10/core/TensorTypeSet.h(44)\u001b[0m: \u001b[01;35mwarning\u001b[0m #68-D: integer conversion resulted in a change of sign\n","\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/vision.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cpu/ROIAlign_cpu.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cpu/nms_cpu.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/SigmoidFocalLoss_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/ROIPool_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_pool_kernel_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_conv_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/BorderAlign_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/nms.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/ROIAlign_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_conv_kernel_cuda.o build/temp.linux-x86_64-3.8/content/STFT/stft_core/csrc/cuda/deform_pool_cuda.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.8/stft_core/_C.cpython-38-x86_64-linux-gnu.so\n","running develop\n","running egg_info\n","creating stft_core.egg-info\n","writing stft_core.egg-info/PKG-INFO\n","writing dependency_links to stft_core.egg-info/dependency_links.txt\n","writing top-level names to stft_core.egg-info/top_level.txt\n","writing manifest file 'stft_core.egg-info/SOURCES.txt'\n","reading manifest file 'stft_core.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","writing manifest file 'stft_core.egg-info/SOURCES.txt'\n","running build_ext\n","copying build/lib.linux-x86_64-3.8/stft_core/_C.cpython-38-x86_64-linux-gnu.so -> stft_core\n","Creating /usr/local/lib/python3.8/dist-packages/stft-core.egg-link (link to .)\n","Adding stft-core 0.1 to easy-install.pth file\n","\n","Installed /content/STFT\n","Processing dependencies for stft-core==0.1\n","Finished processing dependencies for stft-core==0.1\n"]}]},{"cell_type":"code","source":["!pip install 'pillow<7.0.0'\n","!pip install tensorboardX mmcv"],"metadata":{"id":"bXYYwa2u-p7p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676126191776,"user_tz":-60,"elapsed":14581,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"66b3430e-0ac8-4e91-9f41-6bfd17f4d834"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pillow<7.0.0\n","  Downloading Pillow-6.2.2-cp38-cp38-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pillow\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n","fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.5.0 which is incompatible.\n","bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 6.2.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pillow-6.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mmcv\n","  Downloading mmcv-1.7.1.tar.gz (605 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m605.4/605.4 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv) (23.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv) (6.2.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv) (6.0)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.2/190.2 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: mmcv\n","  Building wheel for mmcv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv: filename=mmcv-1.7.1-py2.py3-none-any.whl size=930735 sha256=1e491f885f7032ab80d406594a67b710a407a0cd5507c829e01fdfe50d15bdd6\n","  Stored in directory: /root/.cache/pip/wheels/74/0c/f4/cafa17bca99a907f0ea624325aec45e905dd44884a47eae0bf\n","Successfully built mmcv\n","Installing collected packages: yapf, addict, tensorboardX, mmcv\n","Successfully installed addict-2.4.0 mmcv-1.7.1 tensorboardX-2.5.1 yapf-0.32.0\n"]}]},{"cell_type":"code","source":["# !git clone https://github.com/cocodataset/cocoapi.git\n","# %cd /content/cocoapi/PythonAPI\n","# !python setup.py build_ext install"],"metadata":{"id":"7bNJeAKJNof1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %cd ../..\n","# %ls"],"metadata":{"id":"oZhpvxirOlEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install pytorch==1.3.0 torchvision"],"metadata":{"id":"gkC5c1RMU7Tu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# #!git clone https://github.com/lingyunwu14/STFT.git\n","# %cd /content/STFT\n","# !python setup.py build develop"],"metadata":{"id":"GFZqwzF1NthG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %pip install 'pillow<7.0.0'\n","# %pip install tensorboardX mmcv"],"metadata":{"id":"oDaRiEH2Nwqu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/drive/Othercomputers/\"Mein Computer\"/STFT_git/pretrained_models /content/STFT/pretrained_models"],"metadata":{"id":"e4eRK_rrCRnx","executionInfo":{"status":"ok","timestamp":1676126204824,"user_tz":-60,"elapsed":7568,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Master/Python/data/ASUVideo.zip /content/STFT/datasets/\n","!unzip /content/STFT/datasets/ASUVideo.zip -d /content/STFT/datasets/\n","#!rm /content/SUN_mini_split.zip"],"metadata":{"id":"4Mio7tQ3QodW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676126208200,"user_tz":-60,"elapsed":3380,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"4cb338a1-145e-4a2c-bcec-4e530341ab47"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/STFT/datasets/ASUVideo.zip\n","   creating: /content/STFT/datasets/ASUVideo/Data/\n","   creating: /content/STFT/datasets/ASUVideo/Annotations/\n","  inflating: /content/STFT/datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt  \n","   creating: /content/STFT/datasets/ASUVideo/Data/68-0/\n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-213-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-212-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-211-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-210-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-21-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-209-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-208-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-207-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-206-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-205-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-204-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-203-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-202-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-201-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-200-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-20-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-2-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-199-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-198-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-197-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-196-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-195-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-194-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-193-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-192-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-191-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-190-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-19-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-189-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-188-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-187-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-186-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-185-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-184-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-183-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-182-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-181-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-180-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-18-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-179-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-178-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-177-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-176-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-175-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-174-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-173-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-172-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-171-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-170-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-17-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-169-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-168-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-167-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-166-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-165-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-164-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-163-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-162-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-161-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-160-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-16-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-159-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-158-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-157-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-156-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-155-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-154-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-153-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-152-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-151-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-150-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-15-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-149-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-148-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-147-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-146-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-145-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-144-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-143-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-142-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-141-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-140-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-14-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-139-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-138-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-137-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-136-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-135-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-134-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-133-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-132-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-131-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-130-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-13-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-129-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-128-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-127-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-126-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-125-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-124-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-123-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-122-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-121-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-120-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-12-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-119-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-118-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-117-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-116-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-115-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-114-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-113-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-112-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-111-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-110-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-11-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-109-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-108-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-107-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-106-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-105-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-104-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-103-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-102-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-101-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-100-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-10-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-1-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-96-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-95-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-94-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-93-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-92-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-91-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-90-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-9-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-89-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-88-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-87-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-86-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-85-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-84-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-83-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-82-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-81-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-80-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-8-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-79-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-78-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-77-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-76-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-75-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-74-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-73-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-72-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-71-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-70-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-7-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-69-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-68-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-67-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-66-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-65-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-64-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-63-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-62-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-61-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-60-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-6-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-59-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-58-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-57-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-56-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-55-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-54-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-53-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-52-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-51-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-50-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-5-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-49-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-48-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-47-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-46-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-45-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-44-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-43-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-42-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-41-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-40-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-4-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-39-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-38-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-37-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-36-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-35-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-34-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-33-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-32-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-31-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-30-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-3-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-29-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-28-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-27-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-26-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-259-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-258-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-257-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-256-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-255-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-254-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-253-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-252-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-251-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-250-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-25-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-249-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-248-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-247-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-246-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-245-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-244-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-243-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-242-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-241-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-240-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-24-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-239-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-238-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-237-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-236-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-235-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-234-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-233-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-232-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-231-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-230-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-23-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-229-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-228-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-227-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-226-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-225-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-224-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-223-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-222-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-221-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-220-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-22-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-219-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-218-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-217-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-216-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-215-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-214-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-99-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-98-0.png  \n","  inflating: /content/STFT/datasets/ASUVideo/Data/68-0/68-97-0.png  \n","   creating: /content/STFT/datasets/ASUVideo/Annotations/68-0/\n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-213-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-212-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-211-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-210-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-21-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-209-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-208-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-207-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-206-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-205-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-204-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-203-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-202-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-201-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-200-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-20-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-2-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-199-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-198-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-197-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-196-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-195-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-194-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-193-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-192-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-191-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-190-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-19-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-189-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-188-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-187-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-186-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-185-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-184-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-183-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-182-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-181-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-180-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-18-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-179-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-178-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-177-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-176-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-175-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-174-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-173-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-172-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-171-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-170-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-17-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-169-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-168-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-167-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-166-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-165-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-164-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-163-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-162-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-161-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-160-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-16-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-159-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-158-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-157-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-156-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-155-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-154-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-153-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-152-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-151-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-150-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-15-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-149-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-148-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-147-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-146-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-145-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-144-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-143-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-142-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-141-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-140-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-14-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-139-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-138-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-137-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-136-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-135-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-134-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-133-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-132-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-131-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-130-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-13-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-129-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-128-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-127-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-126-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-125-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-124-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-123-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-122-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-121-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-120-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-12-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-119-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-118-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-117-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-116-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-115-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-114-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-113-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-112-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-111-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-110-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-11-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-109-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-108-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-107-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-106-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-105-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-104-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-103-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-102-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-101-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-100-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-10-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-1-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-96-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-95-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-94-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-93-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-92-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-91-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-90-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-9-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-89-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-88-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-87-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-86-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-85-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-84-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-83-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-82-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-81-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-80-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-8-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-79-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-78-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-77-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-76-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-75-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-74-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-73-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-72-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-71-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-70-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-7-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-69-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-68-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-67-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-66-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-65-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-64-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-63-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-62-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-61-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-60-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-6-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-59-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-58-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-57-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-56-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-55-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-54-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-53-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-52-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-51-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-50-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-5-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-49-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-48-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-47-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-46-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-45-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-44-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-43-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-42-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-41-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-40-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-4-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-39-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-38-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-37-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-36-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-35-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-34-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-33-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-32-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-31-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-30-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-3-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-29-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-28-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-27-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-26-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-259-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-258-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-257-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-256-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-255-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-254-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-253-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-252-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-251-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-250-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-25-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-249-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-248-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-247-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-246-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-245-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-244-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-243-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-242-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-241-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-240-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-24-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-239-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-238-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-237-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-236-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-235-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-234-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-233-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-232-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-231-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-230-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-23-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-229-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-228-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-227-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-226-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-225-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-224-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-223-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-222-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-221-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-220-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-22-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-219-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-218-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-217-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-216-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-215-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-214-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-99-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-98-0.xml  \n","  inflating: /content/STFT/datasets/ASUVideo/Annotations/68-0/68-97-0.xml  \n"]}]},{"cell_type":"code","source":["# !ls\n","# !echo $PYTHONPATH\n","# %env PYTHONPATH=/env/python\n","# !echo $PYTHONPATH   \n","# %env PYTHONPATH=/env/python:.\n","# !echo $PYTHONPATH "],"metadata":{"id":"9R8K3KlDuVT_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# torch.cuda.is_available()"],"metadata":{"id":"s3VaPLQ1w3Yd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from torch.utils.cpp_extension import CUDA_HOME\n","# print(CUDA_HOME)"],"metadata":{"id":"ST45ZHOw5JWW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !nvcc --version"],"metadata":{"id":"h2zBgbJ06Nbx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test Inference \n","!python -m torch.distributed.launch \\\n","    --nproc_per_node=1 \\\n","    tools/test_net.py \\\n","    --master_port=$((RANDOM + 10000)) \\\n","    --visulize \\\n","    --config-file configs/STFT/asuvid_R_50_STFT.yaml \\\n","    MODEL.WEIGHT pretrained_models/ASUMayo_STFT_R_50.pth \\\n","    OUTPUT_DIR log_dir/asuvid_R_50_STFT \\\n","    TEST.IMS_PER_BATCH 1"],"metadata":{"id":"5iVNE8TsRxzg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a6cc439-697f-4dc7-ed95-b495d7a8dd64","executionInfo":{"status":"ok","timestamp":1676126405150,"user_tz":-60,"elapsed":183819,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n","  self.stdout = io.open(c2pread, 'rb', bufsize)\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","/content/STFT/stft_core/utils/c2_model_loading.py:160: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  if old_key.find(param) is -1:\n","2023-02-11 14:37:05,729 stft_core INFO: Using 1 GPUs\n","2023-02-11 14:37:05,729 stft_core INFO: AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 0\n","DATASETS:\n","  TEST: ('ASUVideo_val_videos',)\n","  TRAIN: ('ASUVideo_train_videos',)\n","DTYPE: float32\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HORIZONTAL_FLIP_PROB_TRAIN: 0.5\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1333\n","  MAX_SIZE_TRAIN: 1333\n","  MIN_SIZE_TEST: 800\n","  MIN_SIZE_TRAIN: (800,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  BACKBONE:\n","    CONV_BODY: R-50-FPN-RETINANET\n","    FREEZE_CONV_BODY_AT: 2\n","    USE_GN: False\n","  BORDER:\n","    BBOX_STD: [0.5, 0.5, 0.5, 0.5]\n","    IOU_THRESH: 0.6\n","  BORDER_ON: False\n","  CENTERNET:\n","    CHANNEL_HM: 80\n","    CHANNEL_OFFSET: 2\n","    CHANNEL_WH: 2\n","    FIX_RESIZE: False\n","    HEAD_CONV: 64\n","    INPUT_SCALE: 512\n","    NUM_HEADS: 1\n","    RAND_CROP: True\n","    WEIGHT_HM: 1.0\n","    WEIGHT_MASK: 0.1\n","    WEIGHT_OFFSET: 1.0\n","    WEIGHT_WH: 0.1\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FCOS:\n","    CENTERNESS_ON_REG: True\n","    CENTER_SAMPLING_RADIUS: 1.5\n","    FPN_STRIDES: [8, 16, 32, 64, 128]\n","    INFERENCE_TH: 0.05\n","    IOU_LOSS_TYPE: giou\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.6\n","    NORM_REG_TARGETS: True\n","    NUM_CLASSES: 2\n","    NUM_CONVS: 4\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    USE_DCN_IN_TOWER: False\n","  FCOS_ON: True\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNNSTFT\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    GCB: 0.25\n","    NUM_GROUPS: 1\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, True, True, True)\n","    STAGE_WITH_GCB: (False, True, True, True)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: True\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 64\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: False\n","  RETINANET_ON: False\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 81\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: FastRCNNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 512\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.5\n","    DETECTIONS_PER_IMG: 100\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.5\n","    POSITIVE_FRACTION: 0.25\n","    REG_LOSS_DIV_POS: False\n","    SCORE_THRESH: 0.05\n","    USE_FPN: False\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (16,)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: True\n","    FPN_POST_NMS_TOP_N_TEST: 2000\n","    FPN_POST_NMS_TOP_N_TRAIN: 2000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 2000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 12000\n","    REG_LOSS_DIV_POS: False\n","    RPN_HEAD: SingleConvRPNHead\n","    STRADDLE_THRESH: 0\n","    USE_FPN: False\n","  RPN_ONLY: True\n","  STFT:\n","    BBOX_STD: [0.5, 0.5, 0.5, 0.5]\n","    IOU_THRESH: 0.1\n","    OFFSET_WEIGHT_STD: 0.01\n","    REG_BETA: 0.11\n","  STFT_ON: True\n","  USE_SYNCBN: False\n","  VID:\n","    DFF:\n","      MAX_OFFSET: 0\n","      MIN_OFFSET: -9\n","    ENABLE: True\n","    FGFA:\n","      ALL_FRAME_INTERVAL: 19\n","      KEY_FRAME_LOCATION: 9\n","      MAX_OFFSET: 9\n","      MIN_OFFSET: -9\n","      REF_NUM: 2\n","    FLOWNET_WEIGHT: pretrained_models/flownet.ckpt\n","    IGNORE: False\n","    MEGA:\n","      ALL_FRAME_INTERVAL: 25\n","      GLOBAL:\n","        ENABLE: True\n","        RES_STAGE: 1\n","        SHUFFLE: True\n","        SIZE: 10\n","      KEY_FRAME_LOCATION: 12\n","      MAX_OFFSET: 12\n","      MEMORY:\n","        ENABLE: True\n","        SIZE: 25\n","      MIN_OFFSET: -12\n","      RATIO: 0.2\n","      REF_NUM_GLOBAL: 2\n","      REF_NUM_LOCAL: 2\n","      REF_NUM_MEM: 3\n","    METHOD: cvc_stft\n","    RDN:\n","      ALL_FRAME_INTERVAL: 37\n","      KEY_FRAME_LOCATION: 18\n","      MAX_OFFSET: 18\n","      MIN_OFFSET: -18\n","      RATIO: 0.2\n","      REF_NUM: 2\n","    ROI_BOX_HEAD:\n","      ATTENTION:\n","        ADVANCED_STAGE: 0\n","        EMBED_DIM: 64\n","        ENABLE: False\n","        GROUP: 16\n","        STAGE: 2\n","      REDUCE_CHANNEL: False\n","    RPN:\n","      REF_POST_NMS_TOP_N: 75\n","      REF_PRE_NMS_TOP_N: 6000\n","    STFT:\n","      MAX_OFFSET: 9\n","      MIN_OFFSET: -9\n","      TEST_REF_NUM: 10\n","      TRAIN_REF_NUM: 2\n","  WEIGHT: pretrained_models/ASUMayo_STFT_R_50.pth\n","OUTPUT_DIR: log_dir/asuvid_R_50_STFT\n","PATHS_CATALOG: /content/STFT/stft_core/config/paths_catalog.py\n","SOLVER:\n","  BASE_LR: 0.0005\n","  BIAS_LR_FACTOR: 2\n","  CHECKPOINT_PERIOD: 125\n","  GAMMA: 0.5\n","  IMS_PER_BATCH: 1\n","  LR_TYPE: step\n","  MAX_ITER: 6000\n","  MIN_LR: 1e-07\n","  MOMENTUM: 0.9\n","  OPTIMIZER: sgd\n","  STEPS: (4000, 5000, 5500)\n","  TEST_PERIOD: 125\n","  WARMUP_FACTOR: 0.3333333333333333\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0\n","TEST:\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  DETECTIONS_PER_IMG: 300\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  VIS_THR: 0.55\n","2023-02-11 14:37:05,730 stft_core INFO: Collecting env info (might take some time)\n","2023-02-11 14:37:08,071 stft_core INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 20.04.5 LTS\n","GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","CMake version: version 3.22.6\n","\n","Python version: 3.8\n","Is CUDA available: Yes\n","CUDA runtime version: Could not collect\n","GPU models and configuration: GPU 0: Tesla T4\n","Nvidia driver version: 510.47.03\n","cuDNN version: Probably one of the following:\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.4.0\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.6\n","[pip3] torch==1.4.0\n","[pip3] torchaudio==0.13.1+cu116\n","[pip3] torchsummary==1.5.1\n","[pip3] torchtext==0.14.1\n","[pip3] torchvision==0.5.0\n","[conda] Could not collect\n","        Pillow (6.2.2)\n","2023-02-11 14:37:12,595 stft_core.utils.checkpoint INFO: Loading checkpoint from pretrained_models/ASUMayo_STFT_R_50.pth\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                                loaded from backbone.body.layer1.0.bn1.bias                                of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_mean                        loaded from backbone.body.layer1.0.bn1.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.running_var                         loaded from backbone.body.layer1.0.bn1.running_var                         of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                              loaded from backbone.body.layer1.0.bn1.weight                              of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                                loaded from backbone.body.layer1.0.bn2.bias                                of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_mean                        loaded from backbone.body.layer1.0.bn2.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.running_var                         loaded from backbone.body.layer1.0.bn2.running_var                         of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                              loaded from backbone.body.layer1.0.bn2.weight                              of shape (64,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                                loaded from backbone.body.layer1.0.bn3.bias                                of shape (256,)\n","2023-02-11 14:37:12,842 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_mean                        loaded from backbone.body.layer1.0.bn3.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.running_var                         loaded from backbone.body.layer1.0.bn3.running_var                         of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                              loaded from backbone.body.layer1.0.bn3.weight                              of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight                            loaded from backbone.body.layer1.0.conv1.weight                            of shape (64, 64, 1, 1)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight                            loaded from backbone.body.layer1.0.conv2.weight                            of shape (64, 64, 3, 3)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight                            loaded from backbone.body.layer1.0.conv3.weight                            of shape (256, 64, 1, 1)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight                     loaded from backbone.body.layer1.0.downsample.0.weight                     of shape (256, 64, 1, 1)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias                       loaded from backbone.body.layer1.0.downsample.1.bias                       of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_mean               loaded from backbone.body.layer1.0.downsample.1.running_mean               of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.running_var                loaded from backbone.body.layer1.0.downsample.1.running_var                of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight                     loaded from backbone.body.layer1.0.downsample.1.weight                     of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                                loaded from backbone.body.layer1.1.bn1.bias                                of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_mean                        loaded from backbone.body.layer1.1.bn1.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.running_var                         loaded from backbone.body.layer1.1.bn1.running_var                         of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                              loaded from backbone.body.layer1.1.bn1.weight                              of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                                loaded from backbone.body.layer1.1.bn2.bias                                of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_mean                        loaded from backbone.body.layer1.1.bn2.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.running_var                         loaded from backbone.body.layer1.1.bn2.running_var                         of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                              loaded from backbone.body.layer1.1.bn2.weight                              of shape (64,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                                loaded from backbone.body.layer1.1.bn3.bias                                of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_mean                        loaded from backbone.body.layer1.1.bn3.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.running_var                         loaded from backbone.body.layer1.1.bn3.running_var                         of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                              loaded from backbone.body.layer1.1.bn3.weight                              of shape (256,)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight                            loaded from backbone.body.layer1.1.conv1.weight                            of shape (64, 256, 1, 1)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight                            loaded from backbone.body.layer1.1.conv2.weight                            of shape (64, 64, 3, 3)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight                            loaded from backbone.body.layer1.1.conv3.weight                            of shape (256, 64, 1, 1)\n","2023-02-11 14:37:12,843 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                                loaded from backbone.body.layer1.2.bn1.bias                                of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_mean                        loaded from backbone.body.layer1.2.bn1.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.running_var                         loaded from backbone.body.layer1.2.bn1.running_var                         of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                              loaded from backbone.body.layer1.2.bn1.weight                              of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                                loaded from backbone.body.layer1.2.bn2.bias                                of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_mean                        loaded from backbone.body.layer1.2.bn2.running_mean                        of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.running_var                         loaded from backbone.body.layer1.2.bn2.running_var                         of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                              loaded from backbone.body.layer1.2.bn2.weight                              of shape (64,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                                loaded from backbone.body.layer1.2.bn3.bias                                of shape (256,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_mean                        loaded from backbone.body.layer1.2.bn3.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.running_var                         loaded from backbone.body.layer1.2.bn3.running_var                         of shape (256,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                              loaded from backbone.body.layer1.2.bn3.weight                              of shape (256,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight                            loaded from backbone.body.layer1.2.conv1.weight                            of shape (64, 256, 1, 1)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight                            loaded from backbone.body.layer1.2.conv2.weight                            of shape (64, 64, 3, 3)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight                            loaded from backbone.body.layer1.2.conv3.weight                            of shape (256, 64, 1, 1)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                                loaded from backbone.body.layer2.0.bn1.bias                                of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_mean                        loaded from backbone.body.layer2.0.bn1.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.running_var                         loaded from backbone.body.layer2.0.bn1.running_var                         of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                              loaded from backbone.body.layer2.0.bn1.weight                              of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                                loaded from backbone.body.layer2.0.bn2.bias                                of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_mean                        loaded from backbone.body.layer2.0.bn2.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.running_var                         loaded from backbone.body.layer2.0.bn2.running_var                         of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                              loaded from backbone.body.layer2.0.bn2.weight                              of shape (128,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                                loaded from backbone.body.layer2.0.bn3.bias                                of shape (512,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_mean                        loaded from backbone.body.layer2.0.bn3.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.running_var                         loaded from backbone.body.layer2.0.bn3.running_var                         of shape (512,)\n","2023-02-11 14:37:12,844 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                              loaded from backbone.body.layer2.0.bn3.weight                              of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer2.0.context_block.channel_add_conv.0.bias   of shape (128,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.0.weight loaded from backbone.body.layer2.0.context_block.channel_add_conv.0.weight of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer2.0.context_block.channel_add_conv.1.bias   of shape (128, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.1.weight loaded from backbone.body.layer2.0.context_block.channel_add_conv.1.weight of shape (128, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer2.0.context_block.channel_add_conv.3.bias   of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.channel_add_conv.3.weight loaded from backbone.body.layer2.0.context_block.channel_add_conv.3.weight of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.conv_mask.bias            loaded from backbone.body.layer2.0.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.context_block.conv_mask.weight          loaded from backbone.body.layer2.0.context_block.conv_mask.weight          of shape (1, 512, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight                            loaded from backbone.body.layer2.0.conv1.weight                            of shape (128, 256, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv2.conv.weight                       loaded from backbone.body.layer2.0.conv2.conv.weight                       of shape (128, 128, 3, 3)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv2.offset.bias                       loaded from backbone.body.layer2.0.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv2.offset.weight                     loaded from backbone.body.layer2.0.conv2.offset.weight                     of shape (18, 128, 3, 3)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight                            loaded from backbone.body.layer2.0.conv3.weight                            of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight                     loaded from backbone.body.layer2.0.downsample.0.weight                     of shape (512, 256, 1, 1)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias                       loaded from backbone.body.layer2.0.downsample.1.bias                       of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_mean               loaded from backbone.body.layer2.0.downsample.1.running_mean               of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.running_var                loaded from backbone.body.layer2.0.downsample.1.running_var                of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight                     loaded from backbone.body.layer2.0.downsample.1.weight                     of shape (512,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                                loaded from backbone.body.layer2.1.bn1.bias                                of shape (128,)\n","2023-02-11 14:37:12,845 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_mean                        loaded from backbone.body.layer2.1.bn1.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,909 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.running_var                         loaded from backbone.body.layer2.1.bn1.running_var                         of shape (128,)\n","2023-02-11 14:37:12,909 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                              loaded from backbone.body.layer2.1.bn1.weight                              of shape (128,)\n","2023-02-11 14:37:12,909 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                                loaded from backbone.body.layer2.1.bn2.bias                                of shape (128,)\n","2023-02-11 14:37:12,909 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_mean                        loaded from backbone.body.layer2.1.bn2.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.running_var                         loaded from backbone.body.layer2.1.bn2.running_var                         of shape (128,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                              loaded from backbone.body.layer2.1.bn2.weight                              of shape (128,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                                loaded from backbone.body.layer2.1.bn3.bias                                of shape (512,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_mean                        loaded from backbone.body.layer2.1.bn3.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.running_var                         loaded from backbone.body.layer2.1.bn3.running_var                         of shape (512,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                              loaded from backbone.body.layer2.1.bn3.weight                              of shape (512,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer2.1.context_block.channel_add_conv.0.bias   of shape (128,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.0.weight loaded from backbone.body.layer2.1.context_block.channel_add_conv.0.weight of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer2.1.context_block.channel_add_conv.1.bias   of shape (128, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.1.weight loaded from backbone.body.layer2.1.context_block.channel_add_conv.1.weight of shape (128, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer2.1.context_block.channel_add_conv.3.bias   of shape (512,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.channel_add_conv.3.weight loaded from backbone.body.layer2.1.context_block.channel_add_conv.3.weight of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.conv_mask.bias            loaded from backbone.body.layer2.1.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.context_block.conv_mask.weight          loaded from backbone.body.layer2.1.context_block.conv_mask.weight          of shape (1, 512, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight                            loaded from backbone.body.layer2.1.conv1.weight                            of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv2.conv.weight                       loaded from backbone.body.layer2.1.conv2.conv.weight                       of shape (128, 128, 3, 3)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv2.offset.bias                       loaded from backbone.body.layer2.1.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,910 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv2.offset.weight                     loaded from backbone.body.layer2.1.conv2.offset.weight                     of shape (18, 128, 3, 3)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight                            loaded from backbone.body.layer2.1.conv3.weight                            of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                                loaded from backbone.body.layer2.2.bn1.bias                                of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_mean                        loaded from backbone.body.layer2.2.bn1.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.running_var                         loaded from backbone.body.layer2.2.bn1.running_var                         of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                              loaded from backbone.body.layer2.2.bn1.weight                              of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                                loaded from backbone.body.layer2.2.bn2.bias                                of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_mean                        loaded from backbone.body.layer2.2.bn2.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.running_var                         loaded from backbone.body.layer2.2.bn2.running_var                         of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                              loaded from backbone.body.layer2.2.bn2.weight                              of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                                loaded from backbone.body.layer2.2.bn3.bias                                of shape (512,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_mean                        loaded from backbone.body.layer2.2.bn3.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.running_var                         loaded from backbone.body.layer2.2.bn3.running_var                         of shape (512,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                              loaded from backbone.body.layer2.2.bn3.weight                              of shape (512,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer2.2.context_block.channel_add_conv.0.bias   of shape (128,)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.0.weight loaded from backbone.body.layer2.2.context_block.channel_add_conv.0.weight of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,911 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer2.2.context_block.channel_add_conv.1.bias   of shape (128, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.1.weight loaded from backbone.body.layer2.2.context_block.channel_add_conv.1.weight of shape (128, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer2.2.context_block.channel_add_conv.3.bias   of shape (512,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.channel_add_conv.3.weight loaded from backbone.body.layer2.2.context_block.channel_add_conv.3.weight of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.conv_mask.bias            loaded from backbone.body.layer2.2.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.context_block.conv_mask.weight          loaded from backbone.body.layer2.2.context_block.conv_mask.weight          of shape (1, 512, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight                            loaded from backbone.body.layer2.2.conv1.weight                            of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv2.conv.weight                       loaded from backbone.body.layer2.2.conv2.conv.weight                       of shape (128, 128, 3, 3)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv2.offset.bias                       loaded from backbone.body.layer2.2.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv2.offset.weight                     loaded from backbone.body.layer2.2.conv2.offset.weight                     of shape (18, 128, 3, 3)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight                            loaded from backbone.body.layer2.2.conv3.weight                            of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                                loaded from backbone.body.layer2.3.bn1.bias                                of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_mean                        loaded from backbone.body.layer2.3.bn1.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.running_var                         loaded from backbone.body.layer2.3.bn1.running_var                         of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                              loaded from backbone.body.layer2.3.bn1.weight                              of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                                loaded from backbone.body.layer2.3.bn2.bias                                of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_mean                        loaded from backbone.body.layer2.3.bn2.running_mean                        of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.running_var                         loaded from backbone.body.layer2.3.bn2.running_var                         of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                              loaded from backbone.body.layer2.3.bn2.weight                              of shape (128,)\n","2023-02-11 14:37:12,912 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                                loaded from backbone.body.layer2.3.bn3.bias                                of shape (512,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_mean                        loaded from backbone.body.layer2.3.bn3.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.running_var                         loaded from backbone.body.layer2.3.bn3.running_var                         of shape (512,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                              loaded from backbone.body.layer2.3.bn3.weight                              of shape (512,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer2.3.context_block.channel_add_conv.0.bias   of shape (128,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.0.weight loaded from backbone.body.layer2.3.context_block.channel_add_conv.0.weight of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer2.3.context_block.channel_add_conv.1.bias   of shape (128, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.1.weight loaded from backbone.body.layer2.3.context_block.channel_add_conv.1.weight of shape (128, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer2.3.context_block.channel_add_conv.3.bias   of shape (512,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.channel_add_conv.3.weight loaded from backbone.body.layer2.3.context_block.channel_add_conv.3.weight of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.conv_mask.bias            loaded from backbone.body.layer2.3.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.context_block.conv_mask.weight          loaded from backbone.body.layer2.3.context_block.conv_mask.weight          of shape (1, 512, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight                            loaded from backbone.body.layer2.3.conv1.weight                            of shape (128, 512, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv2.conv.weight                       loaded from backbone.body.layer2.3.conv2.conv.weight                       of shape (128, 128, 3, 3)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv2.offset.bias                       loaded from backbone.body.layer2.3.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv2.offset.weight                     loaded from backbone.body.layer2.3.conv2.offset.weight                     of shape (18, 128, 3, 3)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight                            loaded from backbone.body.layer2.3.conv3.weight                            of shape (512, 128, 1, 1)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                                loaded from backbone.body.layer3.0.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_mean                        loaded from backbone.body.layer3.0.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.running_var                         loaded from backbone.body.layer3.0.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                              loaded from backbone.body.layer3.0.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,913 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                                loaded from backbone.body.layer3.0.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_mean                        loaded from backbone.body.layer3.0.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.running_var                         loaded from backbone.body.layer3.0.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                              loaded from backbone.body.layer3.0.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                                loaded from backbone.body.layer3.0.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_mean                        loaded from backbone.body.layer3.0.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.running_var                         loaded from backbone.body.layer3.0.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                              loaded from backbone.body.layer3.0.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.0.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.0.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.0.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.0.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.0.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.0.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.conv_mask.bias            loaded from backbone.body.layer3.0.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.context_block.conv_mask.weight          loaded from backbone.body.layer3.0.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight                            loaded from backbone.body.layer3.0.conv1.weight                            of shape (256, 512, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv2.conv.weight                       loaded from backbone.body.layer3.0.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv2.offset.bias                       loaded from backbone.body.layer3.0.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv2.offset.weight                     loaded from backbone.body.layer3.0.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight                            loaded from backbone.body.layer3.0.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight                     loaded from backbone.body.layer3.0.downsample.0.weight                     of shape (1024, 512, 1, 1)\n","2023-02-11 14:37:12,914 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias                       loaded from backbone.body.layer3.0.downsample.1.bias                       of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_mean               loaded from backbone.body.layer3.0.downsample.1.running_mean               of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.running_var                loaded from backbone.body.layer3.0.downsample.1.running_var                of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight                     loaded from backbone.body.layer3.0.downsample.1.weight                     of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                                loaded from backbone.body.layer3.1.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_mean                        loaded from backbone.body.layer3.1.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.running_var                         loaded from backbone.body.layer3.1.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                              loaded from backbone.body.layer3.1.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                                loaded from backbone.body.layer3.1.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_mean                        loaded from backbone.body.layer3.1.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.running_var                         loaded from backbone.body.layer3.1.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                              loaded from backbone.body.layer3.1.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                                loaded from backbone.body.layer3.1.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_mean                        loaded from backbone.body.layer3.1.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.running_var                         loaded from backbone.body.layer3.1.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                              loaded from backbone.body.layer3.1.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.1.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.1.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.1.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,915 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.1.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.1.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.1.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.conv_mask.bias            loaded from backbone.body.layer3.1.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.context_block.conv_mask.weight          loaded from backbone.body.layer3.1.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight                            loaded from backbone.body.layer3.1.conv1.weight                            of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv2.conv.weight                       loaded from backbone.body.layer3.1.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv2.offset.bias                       loaded from backbone.body.layer3.1.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv2.offset.weight                     loaded from backbone.body.layer3.1.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight                            loaded from backbone.body.layer3.1.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                                loaded from backbone.body.layer3.2.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_mean                        loaded from backbone.body.layer3.2.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.running_var                         loaded from backbone.body.layer3.2.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                              loaded from backbone.body.layer3.2.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                                loaded from backbone.body.layer3.2.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_mean                        loaded from backbone.body.layer3.2.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.running_var                         loaded from backbone.body.layer3.2.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                              loaded from backbone.body.layer3.2.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                                loaded from backbone.body.layer3.2.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_mean                        loaded from backbone.body.layer3.2.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,916 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.running_var                         loaded from backbone.body.layer3.2.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,917 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                              loaded from backbone.body.layer3.2.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,917 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.2.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,917 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.2.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,917 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.2.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,917 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.2.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.2.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.2.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.conv_mask.bias            loaded from backbone.body.layer3.2.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.context_block.conv_mask.weight          loaded from backbone.body.layer3.2.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight                            loaded from backbone.body.layer3.2.conv1.weight                            of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,924 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv2.conv.weight                       loaded from backbone.body.layer3.2.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv2.offset.bias                       loaded from backbone.body.layer3.2.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv2.offset.weight                     loaded from backbone.body.layer3.2.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight                            loaded from backbone.body.layer3.2.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                                loaded from backbone.body.layer3.3.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_mean                        loaded from backbone.body.layer3.3.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.running_var                         loaded from backbone.body.layer3.3.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                              loaded from backbone.body.layer3.3.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                                loaded from backbone.body.layer3.3.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_mean                        loaded from backbone.body.layer3.3.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.running_var                         loaded from backbone.body.layer3.3.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                              loaded from backbone.body.layer3.3.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                                loaded from backbone.body.layer3.3.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_mean                        loaded from backbone.body.layer3.3.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.running_var                         loaded from backbone.body.layer3.3.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                              loaded from backbone.body.layer3.3.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.3.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.3.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,925 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.3.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.3.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.3.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.3.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.conv_mask.bias            loaded from backbone.body.layer3.3.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.context_block.conv_mask.weight          loaded from backbone.body.layer3.3.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight                            loaded from backbone.body.layer3.3.conv1.weight                            of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv2.conv.weight                       loaded from backbone.body.layer3.3.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv2.offset.bias                       loaded from backbone.body.layer3.3.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv2.offset.weight                     loaded from backbone.body.layer3.3.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight                            loaded from backbone.body.layer3.3.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                                loaded from backbone.body.layer3.4.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_mean                        loaded from backbone.body.layer3.4.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.running_var                         loaded from backbone.body.layer3.4.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                              loaded from backbone.body.layer3.4.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                                loaded from backbone.body.layer3.4.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_mean                        loaded from backbone.body.layer3.4.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.running_var                         loaded from backbone.body.layer3.4.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                              loaded from backbone.body.layer3.4.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                                loaded from backbone.body.layer3.4.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_mean                        loaded from backbone.body.layer3.4.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,926 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.running_var                         loaded from backbone.body.layer3.4.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                              loaded from backbone.body.layer3.4.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.4.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.4.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.4.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.4.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.4.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.4.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.conv_mask.bias            loaded from backbone.body.layer3.4.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.context_block.conv_mask.weight          loaded from backbone.body.layer3.4.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight                            loaded from backbone.body.layer3.4.conv1.weight                            of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv2.conv.weight                       loaded from backbone.body.layer3.4.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv2.offset.bias                       loaded from backbone.body.layer3.4.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv2.offset.weight                     loaded from backbone.body.layer3.4.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight                            loaded from backbone.body.layer3.4.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                                loaded from backbone.body.layer3.5.bn1.bias                                of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_mean                        loaded from backbone.body.layer3.5.bn1.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.running_var                         loaded from backbone.body.layer3.5.bn1.running_var                         of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                              loaded from backbone.body.layer3.5.bn1.weight                              of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                                loaded from backbone.body.layer3.5.bn2.bias                                of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_mean                        loaded from backbone.body.layer3.5.bn2.running_mean                        of shape (256,)\n","2023-02-11 14:37:12,927 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.running_var                         loaded from backbone.body.layer3.5.bn2.running_var                         of shape (256,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                              loaded from backbone.body.layer3.5.bn2.weight                              of shape (256,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                                loaded from backbone.body.layer3.5.bn3.bias                                of shape (1024,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_mean                        loaded from backbone.body.layer3.5.bn3.running_mean                        of shape (1024,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.running_var                         loaded from backbone.body.layer3.5.bn3.running_var                         of shape (1024,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                              loaded from backbone.body.layer3.5.bn3.weight                              of shape (1024,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer3.5.context_block.channel_add_conv.0.bias   of shape (256,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.0.weight loaded from backbone.body.layer3.5.context_block.channel_add_conv.0.weight of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer3.5.context_block.channel_add_conv.1.bias   of shape (256, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.1.weight loaded from backbone.body.layer3.5.context_block.channel_add_conv.1.weight of shape (256, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer3.5.context_block.channel_add_conv.3.bias   of shape (1024,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.channel_add_conv.3.weight loaded from backbone.body.layer3.5.context_block.channel_add_conv.3.weight of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.conv_mask.bias            loaded from backbone.body.layer3.5.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.context_block.conv_mask.weight          loaded from backbone.body.layer3.5.context_block.conv_mask.weight          of shape (1, 1024, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight                            loaded from backbone.body.layer3.5.conv1.weight                            of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv2.conv.weight                       loaded from backbone.body.layer3.5.conv2.conv.weight                       of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv2.offset.bias                       loaded from backbone.body.layer3.5.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv2.offset.weight                     loaded from backbone.body.layer3.5.conv2.offset.weight                     of shape (18, 256, 3, 3)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight                            loaded from backbone.body.layer3.5.conv3.weight                            of shape (1024, 256, 1, 1)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                                loaded from backbone.body.layer4.0.bn1.bias                                of shape (512,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_mean                        loaded from backbone.body.layer4.0.bn1.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,928 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.running_var                         loaded from backbone.body.layer4.0.bn1.running_var                         of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                              loaded from backbone.body.layer4.0.bn1.weight                              of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                                loaded from backbone.body.layer4.0.bn2.bias                                of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_mean                        loaded from backbone.body.layer4.0.bn2.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.running_var                         loaded from backbone.body.layer4.0.bn2.running_var                         of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                              loaded from backbone.body.layer4.0.bn2.weight                              of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                                loaded from backbone.body.layer4.0.bn3.bias                                of shape (2048,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_mean                        loaded from backbone.body.layer4.0.bn3.running_mean                        of shape (2048,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.running_var                         loaded from backbone.body.layer4.0.bn3.running_var                         of shape (2048,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                              loaded from backbone.body.layer4.0.bn3.weight                              of shape (2048,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer4.0.context_block.channel_add_conv.0.bias   of shape (512,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.0.weight loaded from backbone.body.layer4.0.context_block.channel_add_conv.0.weight of shape (512, 2048, 1, 1)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer4.0.context_block.channel_add_conv.1.bias   of shape (512, 1, 1)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.1.weight loaded from backbone.body.layer4.0.context_block.channel_add_conv.1.weight of shape (512, 1, 1)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer4.0.context_block.channel_add_conv.3.bias   of shape (2048,)\n","2023-02-11 14:37:12,929 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.channel_add_conv.3.weight loaded from backbone.body.layer4.0.context_block.channel_add_conv.3.weight of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.conv_mask.bias            loaded from backbone.body.layer4.0.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.context_block.conv_mask.weight          loaded from backbone.body.layer4.0.context_block.conv_mask.weight          of shape (1, 2048, 1, 1)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight                            loaded from backbone.body.layer4.0.conv1.weight                            of shape (512, 1024, 1, 1)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv2.conv.weight                       loaded from backbone.body.layer4.0.conv2.conv.weight                       of shape (512, 512, 3, 3)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv2.offset.bias                       loaded from backbone.body.layer4.0.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv2.offset.weight                     loaded from backbone.body.layer4.0.conv2.offset.weight                     of shape (18, 512, 3, 3)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight                            loaded from backbone.body.layer4.0.conv3.weight                            of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight                     loaded from backbone.body.layer4.0.downsample.0.weight                     of shape (2048, 1024, 1, 1)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias                       loaded from backbone.body.layer4.0.downsample.1.bias                       of shape (2048,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_mean               loaded from backbone.body.layer4.0.downsample.1.running_mean               of shape (2048,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.running_var                loaded from backbone.body.layer4.0.downsample.1.running_var                of shape (2048,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight                     loaded from backbone.body.layer4.0.downsample.1.weight                     of shape (2048,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                                loaded from backbone.body.layer4.1.bn1.bias                                of shape (512,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_mean                        loaded from backbone.body.layer4.1.bn1.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.running_var                         loaded from backbone.body.layer4.1.bn1.running_var                         of shape (512,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                              loaded from backbone.body.layer4.1.bn1.weight                              of shape (512,)\n","2023-02-11 14:37:12,930 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                                loaded from backbone.body.layer4.1.bn2.bias                                of shape (512,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_mean                        loaded from backbone.body.layer4.1.bn2.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.running_var                         loaded from backbone.body.layer4.1.bn2.running_var                         of shape (512,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                              loaded from backbone.body.layer4.1.bn2.weight                              of shape (512,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                                loaded from backbone.body.layer4.1.bn3.bias                                of shape (2048,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_mean                        loaded from backbone.body.layer4.1.bn3.running_mean                        of shape (2048,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.running_var                         loaded from backbone.body.layer4.1.bn3.running_var                         of shape (2048,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                              loaded from backbone.body.layer4.1.bn3.weight                              of shape (2048,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer4.1.context_block.channel_add_conv.0.bias   of shape (512,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.0.weight loaded from backbone.body.layer4.1.context_block.channel_add_conv.0.weight of shape (512, 2048, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer4.1.context_block.channel_add_conv.1.bias   of shape (512, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.1.weight loaded from backbone.body.layer4.1.context_block.channel_add_conv.1.weight of shape (512, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer4.1.context_block.channel_add_conv.3.bias   of shape (2048,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.channel_add_conv.3.weight loaded from backbone.body.layer4.1.context_block.channel_add_conv.3.weight of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.conv_mask.bias            loaded from backbone.body.layer4.1.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.context_block.conv_mask.weight          loaded from backbone.body.layer4.1.context_block.conv_mask.weight          of shape (1, 2048, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight                            loaded from backbone.body.layer4.1.conv1.weight                            of shape (512, 2048, 1, 1)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv2.conv.weight                       loaded from backbone.body.layer4.1.conv2.conv.weight                       of shape (512, 512, 3, 3)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv2.offset.bias                       loaded from backbone.body.layer4.1.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,931 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv2.offset.weight                     loaded from backbone.body.layer4.1.conv2.offset.weight                     of shape (18, 512, 3, 3)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight                            loaded from backbone.body.layer4.1.conv3.weight                            of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                                loaded from backbone.body.layer4.2.bn1.bias                                of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_mean                        loaded from backbone.body.layer4.2.bn1.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.running_var                         loaded from backbone.body.layer4.2.bn1.running_var                         of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                              loaded from backbone.body.layer4.2.bn1.weight                              of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                                loaded from backbone.body.layer4.2.bn2.bias                                of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_mean                        loaded from backbone.body.layer4.2.bn2.running_mean                        of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.running_var                         loaded from backbone.body.layer4.2.bn2.running_var                         of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                              loaded from backbone.body.layer4.2.bn2.weight                              of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                                loaded from backbone.body.layer4.2.bn3.bias                                of shape (2048,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_mean                        loaded from backbone.body.layer4.2.bn3.running_mean                        of shape (2048,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.running_var                         loaded from backbone.body.layer4.2.bn3.running_var                         of shape (2048,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                              loaded from backbone.body.layer4.2.bn3.weight                              of shape (2048,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.0.bias   loaded from backbone.body.layer4.2.context_block.channel_add_conv.0.bias   of shape (512,)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.0.weight loaded from backbone.body.layer4.2.context_block.channel_add_conv.0.weight of shape (512, 2048, 1, 1)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.1.bias   loaded from backbone.body.layer4.2.context_block.channel_add_conv.1.bias   of shape (512, 1, 1)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.1.weight loaded from backbone.body.layer4.2.context_block.channel_add_conv.1.weight of shape (512, 1, 1)\n","2023-02-11 14:37:12,932 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.3.bias   loaded from backbone.body.layer4.2.context_block.channel_add_conv.3.bias   of shape (2048,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.channel_add_conv.3.weight loaded from backbone.body.layer4.2.context_block.channel_add_conv.3.weight of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.conv_mask.bias            loaded from backbone.body.layer4.2.context_block.conv_mask.bias            of shape (1,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.context_block.conv_mask.weight          loaded from backbone.body.layer4.2.context_block.conv_mask.weight          of shape (1, 2048, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight                            loaded from backbone.body.layer4.2.conv1.weight                            of shape (512, 2048, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv2.conv.weight                       loaded from backbone.body.layer4.2.conv2.conv.weight                       of shape (512, 512, 3, 3)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv2.offset.bias                       loaded from backbone.body.layer4.2.conv2.offset.bias                       of shape (18,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv2.offset.weight                     loaded from backbone.body.layer4.2.conv2.offset.weight                     of shape (18, 512, 3, 3)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight                            loaded from backbone.body.layer4.2.conv3.weight                            of shape (2048, 512, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.bias                                    loaded from backbone.body.stem.bn1.bias                                    of shape (64,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.running_mean                            loaded from backbone.body.stem.bn1.running_mean                            of shape (64,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.running_var                             loaded from backbone.body.stem.bn1.running_var                             of shape (64,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.weight                                  loaded from backbone.body.stem.bn1.weight                                  of shape (64,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.body.stem.conv1.weight                                loaded from backbone.body.stem.conv1.weight                                of shape (64, 3, 7, 7)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner2.bias                                   loaded from backbone.fpn.fpn_inner2.bias                                   of shape (256,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner2.weight                                 loaded from backbone.fpn.fpn_inner2.weight                                 of shape (256, 512, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner3.bias                                   loaded from backbone.fpn.fpn_inner3.bias                                   of shape (256,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner3.weight                                 loaded from backbone.fpn.fpn_inner3.weight                                 of shape (256, 1024, 1, 1)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner4.bias                                   loaded from backbone.fpn.fpn_inner4.bias                                   of shape (256,)\n","2023-02-11 14:37:12,933 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_inner4.weight                                 loaded from backbone.fpn.fpn_inner4.weight                                 of shape (256, 2048, 1, 1)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer2.bias                                   loaded from backbone.fpn.fpn_layer2.bias                                   of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer2.weight                                 loaded from backbone.fpn.fpn_layer2.weight                                 of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer3.bias                                   loaded from backbone.fpn.fpn_layer3.bias                                   of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer3.weight                                 loaded from backbone.fpn.fpn_layer3.weight                                 of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer4.bias                                   loaded from backbone.fpn.fpn_layer4.bias                                   of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.fpn_layer4.weight                                 loaded from backbone.fpn.fpn_layer4.weight                                 of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.bias                                loaded from backbone.fpn.top_blocks.p6.bias                                of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.top_blocks.p6.weight                              loaded from backbone.fpn.top_blocks.p6.weight                              of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.bias                                loaded from backbone.fpn.top_blocks.p7.bias                                of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: backbone.fpn.top_blocks.p7.weight                              loaded from backbone.fpn.top_blocks.p7.weight                              of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_pred.bias                                        loaded from rpn.head.bbox_pred.bias                                        of shape (4,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_pred.weight                                      loaded from rpn.head.bbox_pred.weight                                      of shape (4, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.0.bias                                     loaded from rpn.head.bbox_tower.0.bias                                     of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.0.weight                                   loaded from rpn.head.bbox_tower.0.weight                                   of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.1.bias                                     loaded from rpn.head.bbox_tower.1.bias                                     of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.1.weight                                   loaded from rpn.head.bbox_tower.1.weight                                   of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.10.bias                                    loaded from rpn.head.bbox_tower.10.bias                                    of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.10.weight                                  loaded from rpn.head.bbox_tower.10.weight                                  of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.3.bias                                     loaded from rpn.head.bbox_tower.3.bias                                     of shape (256,)\n","2023-02-11 14:37:12,934 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.3.weight                                   loaded from rpn.head.bbox_tower.3.weight                                   of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.4.bias                                     loaded from rpn.head.bbox_tower.4.bias                                     of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.4.weight                                   loaded from rpn.head.bbox_tower.4.weight                                   of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.6.bias                                     loaded from rpn.head.bbox_tower.6.bias                                     of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.6.weight                                   loaded from rpn.head.bbox_tower.6.weight                                   of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.7.bias                                     loaded from rpn.head.bbox_tower.7.bias                                     of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.7.weight                                   loaded from rpn.head.bbox_tower.7.weight                                   of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.9.bias                                     loaded from rpn.head.bbox_tower.9.bias                                     of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.bbox_tower.9.weight                                   loaded from rpn.head.bbox_tower.9.weight                                   of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.centerness.bias                                       loaded from rpn.head.centerness.bias                                       of shape (1,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.centerness.weight                                     loaded from rpn.head.centerness.weight                                     of shape (1, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_logits.bias                                       loaded from rpn.head.cls_logits.bias                                       of shape (1,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_logits.weight                                     loaded from rpn.head.cls_logits.weight                                     of shape (1, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.0.bias                                      loaded from rpn.head.cls_tower.0.bias                                      of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.0.weight                                    loaded from rpn.head.cls_tower.0.weight                                    of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.1.bias                                      loaded from rpn.head.cls_tower.1.bias                                      of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.1.weight                                    loaded from rpn.head.cls_tower.1.weight                                    of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.10.bias                                     loaded from rpn.head.cls_tower.10.bias                                     of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.10.weight                                   loaded from rpn.head.cls_tower.10.weight                                   of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.3.bias                                      loaded from rpn.head.cls_tower.3.bias                                      of shape (256,)\n","2023-02-11 14:37:12,935 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.3.weight                                    loaded from rpn.head.cls_tower.3.weight                                    of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.4.bias                                      loaded from rpn.head.cls_tower.4.bias                                      of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.4.weight                                    loaded from rpn.head.cls_tower.4.weight                                    of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.6.bias                                      loaded from rpn.head.cls_tower.6.bias                                      of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.6.weight                                    loaded from rpn.head.cls_tower.6.weight                                    of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.7.bias                                      loaded from rpn.head.cls_tower.7.bias                                      of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.7.weight                                    loaded from rpn.head.cls_tower.7.weight                                    of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.9.bias                                      loaded from rpn.head.cls_tower.9.bias                                      of shape (256,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.cls_tower.9.weight                                    loaded from rpn.head.cls_tower.9.weight                                    of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_bbox_pred.bias                                    loaded from rpn.head.dcn_bbox_pred.bias                                    of shape (4,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_bbox_pred.weight                                  loaded from rpn.head.dcn_bbox_pred.weight                                  of shape (4, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_bbox_subnet.conv_adaption.weight                  loaded from rpn.head.dcn_bbox_subnet.conv_adaption.weight                  of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_bbox_subnet.conv_offset.weight                    loaded from rpn.head.dcn_bbox_subnet.conv_offset.weight                    of shape (72, 4, 1, 1)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_cls_score.bias                                    loaded from rpn.head.dcn_cls_score.bias                                    of shape (1,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_cls_score.weight                                  loaded from rpn.head.dcn_cls_score.weight                                  of shape (1, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_cls_subnet.conv_adaption.weight                   loaded from rpn.head.dcn_cls_subnet.conv_adaption.weight                   of shape (256, 256, 3, 3)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.dcn_cls_subnet.conv_offset.weight                     loaded from rpn.head.dcn_cls_subnet.conv_offset.weight                     of shape (72, 4, 1, 1)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.scales.0.scale                                        loaded from rpn.head.scales.0.scale                                        of shape (1,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.scales.1.scale                                        loaded from rpn.head.scales.1.scale                                        of shape (1,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.scales.2.scale                                        loaded from rpn.head.scales.2.scale                                        of shape (1,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.scales.3.scale                                        loaded from rpn.head.scales.3.scale                                        of shape (1,)\n","2023-02-11 14:37:12,936 stft_core.utils.model_serialization INFO: rpn.head.scales.4.scale                                        loaded from rpn.head.scales.4.scale                                        of shape (1,)\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","Had processed 0 images\n","Had processed 259 images\n","Saving ASUVideo's annotation information into datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7fe620c31220>\n","2023-02-11 14:37:13,052 stft_core.inference INFO: Start evaluation on ASUVideo_val_videos dataset(259 images).\n","100% 259/259 [02:48<00:00,  1.54it/s]\n","2023-02-11 14:40:01,140 stft_core.inference INFO: Total run time: 0:02:48.087389 (0.6489860588059002 s / img per device, on 1 devices)\n","2023-02-11 14:40:01,140 stft_core.inference INFO: Model inference time: 0:02:46.715058 (0.6436874838869544 s / img per device, on 1 devices)\n","2023-02-11 14:40:01,160 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 14:40:01,252 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 14:40:01,256 stft_core.inference INFO: \n","score_thr:0.60  Precision: 98.9011   Recall: 95.2381   Accuracy: 95.7529   Sepcificity: 97.1429   F1_score: 97.0350   F2_score: 95.9488 \n","2023-02-11 14:40:01,257 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 14:40:01,265 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 95.2381   F1_score: 97.5610   F2_score: 96.1538 \n"]}]},{"cell_type":"code","source":["# Training\n","!python -m torch.distributed.launch \\\n","    --nproc_per_node=1 \\\n","    tools/train_net.py \\\n","    --master_port=$((RANDOM + 10000)) \\\n","    --config-file configs/STFT/asuvid_R_50_STFT.yaml \\\n","    OUTPUT_DIR log_dir/asuvid_R_50_STFT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1iwqqlSNcUQ","executionInfo":{"status":"ok","timestamp":1676128508295,"user_tz":-60,"elapsed":1889578,"user":{"displayName":"Joshua Friedrich","userId":"15841861997058434935"}},"outputId":"cd6cb526-d3b6-4177-9e03-0ae81796e6ce"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n","  self.stdout = io.open(c2pread, 'rb', bufsize)\n","/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n","train.py, WORLD_SIZE:  1\n","True\n","1\n","Tesla T4\n","0\n","2023-02-11 14:43:42,412 stft_core INFO: Using 1 GPUs\n","2023-02-11 14:43:42,412 stft_core INFO: Namespace(config_file='configs/STFT/asuvid_R_50_STFT.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29972', opts=['OUTPUT_DIR', 'log_dir/asuvid_R_50_STFT'])\n","2023-02-11 14:43:42,412 stft_core INFO: Collecting env info (might take some time)\n","2023-02-11 14:43:44,388 stft_core INFO: \n","PyTorch version: 1.4.0\n","Is debug build: No\n","CUDA used to build PyTorch: 10.1\n","\n","OS: Ubuntu 20.04.5 LTS\n","GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","CMake version: version 3.22.6\n","\n","Python version: 3.8\n","Is CUDA available: Yes\n","CUDA runtime version: Could not collect\n","GPU models and configuration: GPU 0: Tesla T4\n","Nvidia driver version: 510.47.03\n","cuDNN version: Probably one of the following:\n","/usr/lib/x86_64-linux-gnu/libcudnn.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.4.0\n","/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.4.0\n","\n","Versions of relevant libraries:\n","[pip3] numpy==1.21.6\n","[pip3] torch==1.4.0\n","[pip3] torchaudio==0.13.1+cu116\n","[pip3] torchsummary==1.5.1\n","[pip3] torchtext==0.14.1\n","[pip3] torchvision==0.5.0\n","[conda] Could not collect\n","        Pillow (6.2.2)\n","2023-02-11 14:43:44,388 stft_core INFO: Loaded configuration file configs/STFT/asuvid_R_50_STFT.yaml\n","2023-02-11 14:43:44,389 stft_core INFO: Running with config:\n","AMP_VERBOSE: False\n","DATALOADER:\n","  ASPECT_RATIO_GROUPING: True\n","  NUM_WORKERS: 4\n","  SIZE_DIVISIBILITY: 0\n","DATASETS:\n","  TEST: ('ASUVideo_val_videos',)\n","  TRAIN: ('ASUVideo_train_videos',)\n","DTYPE: float32\n","INPUT:\n","  BRIGHTNESS: 0.0\n","  CONTRAST: 0.0\n","  HORIZONTAL_FLIP_PROB_TRAIN: 0.5\n","  HUE: 0.0\n","  MAX_SIZE_TEST: 1333\n","  MAX_SIZE_TRAIN: 1333\n","  MIN_SIZE_TEST: 800\n","  MIN_SIZE_TRAIN: (800,)\n","  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]\n","  PIXEL_STD: [1.0, 1.0, 1.0]\n","  SATURATION: 0.0\n","  TO_BGR255: True\n","  VERTICAL_FLIP_PROB_TRAIN: 0.0\n","MODEL:\n","  BACKBONE:\n","    CONV_BODY: R-50-FPN-RETINANET\n","    FREEZE_CONV_BODY_AT: 2\n","    USE_GN: False\n","  BORDER:\n","    BBOX_STD: [0.5, 0.5, 0.5, 0.5]\n","    IOU_THRESH: 0.6\n","  BORDER_ON: False\n","  CENTERNET:\n","    CHANNEL_HM: 80\n","    CHANNEL_OFFSET: 2\n","    CHANNEL_WH: 2\n","    FIX_RESIZE: False\n","    HEAD_CONV: 64\n","    INPUT_SCALE: 512\n","    NUM_HEADS: 1\n","    RAND_CROP: True\n","    WEIGHT_HM: 1.0\n","    WEIGHT_MASK: 0.1\n","    WEIGHT_OFFSET: 1.0\n","    WEIGHT_WH: 0.1\n","  CLS_AGNOSTIC_BBOX_REG: False\n","  DEVICE: cuda\n","  FBNET:\n","    ARCH: default\n","    ARCH_DEF: \n","    BN_TYPE: bn\n","    DET_HEAD_BLOCKS: []\n","    DET_HEAD_LAST_SCALE: 1.0\n","    DET_HEAD_STRIDE: 0\n","    DW_CONV_SKIP_BN: True\n","    DW_CONV_SKIP_RELU: True\n","    KPTS_HEAD_BLOCKS: []\n","    KPTS_HEAD_LAST_SCALE: 0.0\n","    KPTS_HEAD_STRIDE: 0\n","    MASK_HEAD_BLOCKS: []\n","    MASK_HEAD_LAST_SCALE: 0.0\n","    MASK_HEAD_STRIDE: 0\n","    RPN_BN_TYPE: \n","    RPN_HEAD_BLOCKS: 0\n","    SCALE_FACTOR: 1.0\n","    WIDTH_DIVISOR: 1\n","  FCOS:\n","    CENTERNESS_ON_REG: True\n","    CENTER_SAMPLING_RADIUS: 1.5\n","    FPN_STRIDES: [8, 16, 32, 64, 128]\n","    INFERENCE_TH: 0.05\n","    IOU_LOSS_TYPE: giou\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.6\n","    NORM_REG_TARGETS: True\n","    NUM_CLASSES: 2\n","    NUM_CONVS: 4\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    USE_DCN_IN_TOWER: False\n","  FCOS_ON: True\n","  FPN:\n","    USE_GN: False\n","    USE_RELU: False\n","  GROUP_NORM:\n","    DIM_PER_GP: -1\n","    EPSILON: 1e-05\n","    NUM_GROUPS: 32\n","  KEYPOINT_ON: False\n","  MASK_ON: False\n","  META_ARCHITECTURE: GeneralizedRCNNSTFT\n","  RESNETS:\n","    BACKBONE_OUT_CHANNELS: 256\n","    DEFORMABLE_GROUPS: 1\n","    GCB: 0.25\n","    NUM_GROUPS: 1\n","    RES2_OUT_CHANNELS: 256\n","    RES5_DILATION: 1\n","    STAGE_WITH_DCN: (False, True, True, True)\n","    STAGE_WITH_GCB: (False, True, True, True)\n","    STEM_FUNC: StemWithFixedBatchNorm\n","    STEM_OUT_CHANNELS: 64\n","    STRIDE_IN_1X1: True\n","    TRANS_FUNC: BottleneckWithFixedBatchNorm\n","    WIDTH_PER_GROUP: 64\n","    WITH_MODULATED_DCN: False\n","  RETINANET:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDES: (8, 16, 32, 64, 128)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BBOX_REG_BETA: 0.11\n","    BBOX_REG_WEIGHT: 4.0\n","    BG_IOU_THRESHOLD: 0.4\n","    FG_IOU_THRESHOLD: 0.5\n","    INFERENCE_TH: 0.05\n","    LOSS_ALPHA: 0.25\n","    LOSS_GAMMA: 2.0\n","    NMS_TH: 0.4\n","    NUM_CLASSES: 81\n","    NUM_CONVS: 4\n","    OCTAVE: 2.0\n","    PRE_NMS_TOP_N: 1000\n","    PRIOR_PROB: 0.01\n","    SCALES_PER_OCTAVE: 3\n","    STRADDLE_THRESH: 0\n","    USE_C5: False\n","  RETINANET_ON: False\n","  ROI_BOX_HEAD:\n","    CONV_HEAD_DIM: 256\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 81\n","    NUM_STACKED_CONVS: 4\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: FastRCNNPredictor\n","    USE_GN: False\n","  ROI_HEADS:\n","    BATCH_SIZE_PER_IMAGE: 512\n","    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n","    BG_IOU_THRESHOLD: 0.5\n","    DETECTIONS_PER_IMG: 100\n","    FG_IOU_THRESHOLD: 0.5\n","    NMS: 0.5\n","    POSITIVE_FRACTION: 0.25\n","    REG_LOSS_DIV_POS: False\n","    SCORE_THRESH: 0.05\n","    USE_FPN: False\n","  ROI_KEYPOINT_HEAD:\n","    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)\n","    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    NUM_CLASSES: 17\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    PREDICTOR: KeypointRCNNPredictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","  ROI_MASK_HEAD:\n","    CONV_LAYERS: (256, 256, 256, 256)\n","    DILATION: 1\n","    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor\n","    MLP_HEAD_DIM: 1024\n","    POOLER_RESOLUTION: 14\n","    POOLER_SAMPLING_RATIO: 0\n","    POOLER_SCALES: (0.0625,)\n","    POSTPROCESS_MASKS: False\n","    POSTPROCESS_MASKS_THRESHOLD: 0.5\n","    PREDICTOR: MaskRCNNC4Predictor\n","    RESOLUTION: 14\n","    SHARE_BOX_FEATURE_EXTRACTOR: True\n","    USE_GN: False\n","  RPN:\n","    ANCHOR_SIZES: (32, 64, 128, 256, 512)\n","    ANCHOR_STRIDE: (16,)\n","    ASPECT_RATIOS: (0.5, 1.0, 2.0)\n","    BATCH_SIZE_PER_IMAGE: 256\n","    BG_IOU_THRESHOLD: 0.3\n","    FG_IOU_THRESHOLD: 0.7\n","    FPN_POST_NMS_PER_BATCH: True\n","    FPN_POST_NMS_TOP_N_TEST: 2000\n","    FPN_POST_NMS_TOP_N_TRAIN: 2000\n","    MIN_SIZE: 0\n","    NMS_THRESH: 0.7\n","    POSITIVE_FRACTION: 0.5\n","    POST_NMS_TOP_N_TEST: 1000\n","    POST_NMS_TOP_N_TRAIN: 2000\n","    PRE_NMS_TOP_N_TEST: 6000\n","    PRE_NMS_TOP_N_TRAIN: 12000\n","    REG_LOSS_DIV_POS: False\n","    RPN_HEAD: SingleConvRPNHead\n","    STRADDLE_THRESH: 0\n","    USE_FPN: False\n","  RPN_ONLY: True\n","  STFT:\n","    BBOX_STD: [0.5, 0.5, 0.5, 0.5]\n","    IOU_THRESH: 0.1\n","    OFFSET_WEIGHT_STD: 0.01\n","    REG_BETA: 0.11\n","  STFT_ON: True\n","  USE_SYNCBN: False\n","  VID:\n","    DFF:\n","      MAX_OFFSET: 0\n","      MIN_OFFSET: -9\n","    ENABLE: True\n","    FGFA:\n","      ALL_FRAME_INTERVAL: 19\n","      KEY_FRAME_LOCATION: 9\n","      MAX_OFFSET: 9\n","      MIN_OFFSET: -9\n","      REF_NUM: 2\n","    FLOWNET_WEIGHT: pretrained_models/flownet.ckpt\n","    IGNORE: False\n","    MEGA:\n","      ALL_FRAME_INTERVAL: 25\n","      GLOBAL:\n","        ENABLE: True\n","        RES_STAGE: 1\n","        SHUFFLE: True\n","        SIZE: 10\n","      KEY_FRAME_LOCATION: 12\n","      MAX_OFFSET: 12\n","      MEMORY:\n","        ENABLE: True\n","        SIZE: 25\n","      MIN_OFFSET: -12\n","      RATIO: 0.2\n","      REF_NUM_GLOBAL: 2\n","      REF_NUM_LOCAL: 2\n","      REF_NUM_MEM: 3\n","    METHOD: cvc_stft\n","    RDN:\n","      ALL_FRAME_INTERVAL: 37\n","      KEY_FRAME_LOCATION: 18\n","      MAX_OFFSET: 18\n","      MIN_OFFSET: -18\n","      RATIO: 0.2\n","      REF_NUM: 2\n","    ROI_BOX_HEAD:\n","      ATTENTION:\n","        ADVANCED_STAGE: 0\n","        EMBED_DIM: 64\n","        ENABLE: False\n","        GROUP: 16\n","        STAGE: 2\n","      REDUCE_CHANNEL: False\n","    RPN:\n","      REF_POST_NMS_TOP_N: 75\n","      REF_PRE_NMS_TOP_N: 6000\n","    STFT:\n","      MAX_OFFSET: 9\n","      MIN_OFFSET: -9\n","      TEST_REF_NUM: 10\n","      TRAIN_REF_NUM: 2\n","  WEIGHT: catalog://ImageNetPretrained/MSRA/R-50\n","OUTPUT_DIR: log_dir/asuvid_R_50_STFT\n","PATHS_CATALOG: /content/STFT/stft_core/config/paths_catalog.py\n","SOLVER:\n","  BASE_LR: 0.0005\n","  BIAS_LR_FACTOR: 2\n","  CHECKPOINT_PERIOD: 125\n","  GAMMA: 0.5\n","  IMS_PER_BATCH: 1\n","  LR_TYPE: step\n","  MAX_ITER: 6000\n","  MIN_LR: 1e-07\n","  MOMENTUM: 0.9\n","  OPTIMIZER: sgd\n","  STEPS: (4000, 5000, 5500)\n","  TEST_PERIOD: 125\n","  WARMUP_FACTOR: 0.3333333333333333\n","  WARMUP_ITERS: 500\n","  WARMUP_METHOD: linear\n","  WEIGHT_DECAY: 0.0001\n","  WEIGHT_DECAY_BIAS: 0\n","TEST:\n","  BBOX_AUG:\n","    ENABLED: False\n","    H_FLIP: False\n","    MAX_SIZE: 4000\n","    SCALES: ()\n","    SCALE_H_FLIP: False\n","  DETECTIONS_PER_IMG: 300\n","  EXPECTED_RESULTS: []\n","  EXPECTED_RESULTS_SIGMA_TOL: 4\n","  IMS_PER_BATCH: 1\n","  VIS_THR: 0.55\n","2023-02-11 14:43:44,389 stft_core INFO: Saving config into: log_dir/asuvid_R_50_STFT/config.yml\n","2023-02-11 14:43:48,267 stft_core INFO: \n","model:\n","GeneralizedRCNNSTFT(\n","  (backbone): Sequential(\n","    (body): ResNet(\n","      (stem): StemWithFixedBatchNorm(\n","        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","        (bn1): FrozenBatchNorm2d()\n","      )\n","      (layer1): Sequential(\n","        (0): BottleneckWithFixedBatchNorm(\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d()\n","          )\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","        )\n","        (1): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","        )\n","        (2): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): BottleneckWithFixedBatchNorm(\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d()\n","          )\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((128, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((128, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((128, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (3): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(128, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=128, out_channels=128, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((128, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): BottleneckWithFixedBatchNorm(\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d()\n","          )\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (3): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (4): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (5): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(256, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((256, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): BottleneckWithFixedBatchNorm(\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d()\n","          )\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((512, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (1): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((512, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","        (2): BottleneckWithFixedBatchNorm(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d()\n","          (conv2): DFConv2d(\n","            (offset): Conv2d(512, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","            (conv): DeformConv(in_channels=512, out_channels=512, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=1, bias=False)\n","          )\n","          (bn2): FrozenBatchNorm2d()\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d()\n","          (context_block): ContextBlock(\n","            (conv_mask): Conv2d(2048, 1, kernel_size=(1, 1), stride=(1, 1))\n","            (softmax): Softmax(dim=2)\n","            (channel_add_conv): Sequential(\n","              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","              (1): LayerNorm((512, 1, 1), eps=1e-05, elementwise_affine=True)\n","              (2): ReLU(inplace=True)\n","              (3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (fpn): FPN(\n","      (fpn_inner2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (fpn_inner3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (fpn_inner4): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (top_blocks): LastLevelP6P7(\n","        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (rpn): STFTFCOSModule(\n","    (head): STFTFCOSHead(\n","      (cls_tower): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (2): ReLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (5): ReLU()\n","        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (8): ReLU()\n","        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (11): ReLU()\n","      )\n","      (bbox_tower): Sequential(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (2): ReLU()\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (5): ReLU()\n","        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (8): ReLU()\n","        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n","        (11): ReLU()\n","      )\n","      (cls_logits): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (bbox_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (centerness): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (dcn_cls_subnet): SFTBranch(\n","        (conv_offset): Conv2d(4, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (conv_adaption): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=4, bias=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (dcn_bbox_subnet): SFTBranch(\n","        (conv_offset): Conv2d(4, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (conv_adaption): DeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(1, 1), groups=1, deformable_groups=4, bias=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (dcn_cls_score): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (dcn_bbox_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (scales): ModuleList(\n","        (0): Scale()\n","        (1): Scale()\n","        (2): Scale()\n","        (3): Scale()\n","        (4): Scale()\n","      )\n","    )\n","    (box_selector_test): STFTFCOSPostProcessor()\n","  )\n",")\n","2023-02-11 14:43:48,300 stft_core.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-50\n","2023-02-11 14:43:48,300 stft_core.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-50 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl\n","Downloading: \"https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl\" to /root/.torch/models/R-50.pkl\n","100% 97.6M/97.6M [00:02<00:00, 47.5MB/s]\n","2023-02-11 14:43:50,987 stft_core.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-50.pkl cached in /root/.torch/models/R-50.pkl\n","2023-02-11 14:43:51,073 stft_core.utils.c2_model_loading INFO: Remapping C2 weights\n","2023-02-11 14:43:51,073 stft_core.utils.c2_model_loading INFO: C2 name: conv1_b              mapped name: conv1.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: conv1_w              mapped name: conv1.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: fc1000_b             mapped name: fc1000.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: fc1000_w             mapped name: fc1000.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b     mapped name: layer1.0.downsample.0.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b  mapped name: layer1.0.downsample.1.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s  mapped name: layer1.0.downsample.1.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w     mapped name: layer1.0.downsample.0.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b    mapped name: layer1.0.conv1.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b mapped name: layer1.0.bn1.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s mapped name: layer1.0.bn1.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w    mapped name: layer1.0.conv1.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b    mapped name: layer1.0.conv2.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b mapped name: layer1.0.bn2.bias\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s mapped name: layer1.0.bn2.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w    mapped name: layer1.0.conv2.weight\n","2023-02-11 14:43:51,074 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b    mapped name: layer1.0.conv3.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b mapped name: layer1.0.bn3.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s mapped name: layer1.0.bn3.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w    mapped name: layer1.0.conv3.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b    mapped name: layer1.1.conv1.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b mapped name: layer1.1.bn1.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s mapped name: layer1.1.bn1.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w    mapped name: layer1.1.conv1.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b    mapped name: layer1.1.conv2.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b mapped name: layer1.1.bn2.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s mapped name: layer1.1.bn2.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w    mapped name: layer1.1.conv2.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b    mapped name: layer1.1.conv3.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b mapped name: layer1.1.bn3.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s mapped name: layer1.1.bn3.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w    mapped name: layer1.1.conv3.weight\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b    mapped name: layer1.2.conv1.bias\n","2023-02-11 14:43:51,075 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b mapped name: layer1.2.bn1.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s mapped name: layer1.2.bn1.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w    mapped name: layer1.2.conv1.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b    mapped name: layer1.2.conv2.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b mapped name: layer1.2.bn2.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s mapped name: layer1.2.bn2.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w    mapped name: layer1.2.conv2.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b    mapped name: layer1.2.conv3.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b mapped name: layer1.2.bn3.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s mapped name: layer1.2.bn3.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w    mapped name: layer1.2.conv3.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b     mapped name: layer2.0.downsample.0.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b  mapped name: layer2.0.downsample.1.bias\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s  mapped name: layer2.0.downsample.1.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w     mapped name: layer2.0.downsample.0.weight\n","2023-02-11 14:43:51,076 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b    mapped name: layer2.0.conv1.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b mapped name: layer2.0.bn1.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s mapped name: layer2.0.bn1.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w    mapped name: layer2.0.conv1.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b    mapped name: layer2.0.conv2.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b mapped name: layer2.0.bn2.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s mapped name: layer2.0.bn2.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w    mapped name: layer2.0.conv2.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b    mapped name: layer2.0.conv3.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b mapped name: layer2.0.bn3.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s mapped name: layer2.0.bn3.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w    mapped name: layer2.0.conv3.weight\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b    mapped name: layer2.1.conv1.bias\n","2023-02-11 14:43:51,077 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b mapped name: layer2.1.bn1.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s mapped name: layer2.1.bn1.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w    mapped name: layer2.1.conv1.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b    mapped name: layer2.1.conv2.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b mapped name: layer2.1.bn2.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s mapped name: layer2.1.bn2.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w    mapped name: layer2.1.conv2.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b    mapped name: layer2.1.conv3.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b mapped name: layer2.1.bn3.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s mapped name: layer2.1.bn3.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w    mapped name: layer2.1.conv3.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b    mapped name: layer2.2.conv1.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b mapped name: layer2.2.bn1.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s mapped name: layer2.2.bn1.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w    mapped name: layer2.2.conv1.weight\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b    mapped name: layer2.2.conv2.bias\n","2023-02-11 14:43:51,078 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b mapped name: layer2.2.bn2.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s mapped name: layer2.2.bn2.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w    mapped name: layer2.2.conv2.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b    mapped name: layer2.2.conv3.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b mapped name: layer2.2.bn3.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s mapped name: layer2.2.bn3.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w    mapped name: layer2.2.conv3.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b    mapped name: layer2.3.conv1.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b mapped name: layer2.3.bn1.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s mapped name: layer2.3.bn1.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w    mapped name: layer2.3.conv1.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b    mapped name: layer2.3.conv2.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b mapped name: layer2.3.bn2.bias\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s mapped name: layer2.3.bn2.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w    mapped name: layer2.3.conv2.weight\n","2023-02-11 14:43:51,079 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b    mapped name: layer2.3.conv3.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b mapped name: layer2.3.bn3.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s mapped name: layer2.3.bn3.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w    mapped name: layer2.3.conv3.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b     mapped name: layer3.0.downsample.0.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b  mapped name: layer3.0.downsample.1.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s  mapped name: layer3.0.downsample.1.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w     mapped name: layer3.0.downsample.0.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b    mapped name: layer3.0.conv1.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b mapped name: layer3.0.bn1.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s mapped name: layer3.0.bn1.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w    mapped name: layer3.0.conv1.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b    mapped name: layer3.0.conv2.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b mapped name: layer3.0.bn2.bias\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s mapped name: layer3.0.bn2.weight\n","2023-02-11 14:43:51,080 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w    mapped name: layer3.0.conv2.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b    mapped name: layer3.0.conv3.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b mapped name: layer3.0.bn3.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s mapped name: layer3.0.bn3.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w    mapped name: layer3.0.conv3.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b    mapped name: layer3.1.conv1.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b mapped name: layer3.1.bn1.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s mapped name: layer3.1.bn1.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w    mapped name: layer3.1.conv1.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b    mapped name: layer3.1.conv2.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b mapped name: layer3.1.bn2.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s mapped name: layer3.1.bn2.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w    mapped name: layer3.1.conv2.weight\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b    mapped name: layer3.1.conv3.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b mapped name: layer3.1.bn3.bias\n","2023-02-11 14:43:51,081 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s mapped name: layer3.1.bn3.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w    mapped name: layer3.1.conv3.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b    mapped name: layer3.2.conv1.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b mapped name: layer3.2.bn1.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s mapped name: layer3.2.bn1.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w    mapped name: layer3.2.conv1.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b    mapped name: layer3.2.conv2.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b mapped name: layer3.2.bn2.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s mapped name: layer3.2.bn2.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w    mapped name: layer3.2.conv2.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b    mapped name: layer3.2.conv3.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b mapped name: layer3.2.bn3.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s mapped name: layer3.2.bn3.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w    mapped name: layer3.2.conv3.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b    mapped name: layer3.3.conv1.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b mapped name: layer3.3.bn1.bias\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s mapped name: layer3.3.bn1.weight\n","2023-02-11 14:43:51,082 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w    mapped name: layer3.3.conv1.weight\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b    mapped name: layer3.3.conv2.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b mapped name: layer3.3.bn2.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s mapped name: layer3.3.bn2.weight\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w    mapped name: layer3.3.conv2.weight\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b    mapped name: layer3.3.conv3.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b mapped name: layer3.3.bn3.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s mapped name: layer3.3.bn3.weight\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w    mapped name: layer3.3.conv3.weight\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b    mapped name: layer3.4.conv1.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b mapped name: layer3.4.bn1.bias\n","2023-02-11 14:43:51,083 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s mapped name: layer3.4.bn1.weight\n","2023-02-11 14:43:51,098 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w    mapped name: layer3.4.conv1.weight\n","2023-02-11 14:43:51,098 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b    mapped name: layer3.4.conv2.bias\n","2023-02-11 14:43:51,098 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b mapped name: layer3.4.bn2.bias\n","2023-02-11 14:43:51,098 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s mapped name: layer3.4.bn2.weight\n","2023-02-11 14:43:51,098 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w    mapped name: layer3.4.conv2.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b    mapped name: layer3.4.conv3.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b mapped name: layer3.4.bn3.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s mapped name: layer3.4.bn3.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w    mapped name: layer3.4.conv3.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b    mapped name: layer3.5.conv1.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b mapped name: layer3.5.bn1.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s mapped name: layer3.5.bn1.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w    mapped name: layer3.5.conv1.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b    mapped name: layer3.5.conv2.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b mapped name: layer3.5.bn2.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s mapped name: layer3.5.bn2.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w    mapped name: layer3.5.conv2.weight\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b    mapped name: layer3.5.conv3.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b mapped name: layer3.5.bn3.bias\n","2023-02-11 14:43:51,099 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s mapped name: layer3.5.bn3.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w    mapped name: layer3.5.conv3.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b     mapped name: layer4.0.downsample.0.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b  mapped name: layer4.0.downsample.1.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s  mapped name: layer4.0.downsample.1.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w     mapped name: layer4.0.downsample.0.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b    mapped name: layer4.0.conv1.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b mapped name: layer4.0.bn1.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s mapped name: layer4.0.bn1.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w    mapped name: layer4.0.conv1.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b    mapped name: layer4.0.conv2.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b mapped name: layer4.0.bn2.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s mapped name: layer4.0.bn2.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w    mapped name: layer4.0.conv2.weight\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b    mapped name: layer4.0.conv3.bias\n","2023-02-11 14:43:51,100 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b mapped name: layer4.0.bn3.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s mapped name: layer4.0.bn3.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w    mapped name: layer4.0.conv3.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b    mapped name: layer4.1.conv1.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b mapped name: layer4.1.bn1.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s mapped name: layer4.1.bn1.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w    mapped name: layer4.1.conv1.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b    mapped name: layer4.1.conv2.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b mapped name: layer4.1.bn2.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s mapped name: layer4.1.bn2.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w    mapped name: layer4.1.conv2.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b    mapped name: layer4.1.conv3.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b mapped name: layer4.1.bn3.bias\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s mapped name: layer4.1.bn3.weight\n","2023-02-11 14:43:51,101 stft_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w    mapped name: layer4.1.conv3.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b    mapped name: layer4.2.conv1.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b mapped name: layer4.2.bn1.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s mapped name: layer4.2.bn1.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w    mapped name: layer4.2.conv1.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b    mapped name: layer4.2.conv2.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b mapped name: layer4.2.bn2.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s mapped name: layer4.2.bn2.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w    mapped name: layer4.2.conv2.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b    mapped name: layer4.2.conv3.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b mapped name: layer4.2.bn3.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s mapped name: layer4.2.bn3.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w    mapped name: layer4.2.conv3.weight\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b       mapped name: bn1.bias\n","2023-02-11 14:43:51,102 stft_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s       mapped name: bn1.weight\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.0.conv2.bias, new_key: layer2.0.conv2.conv.bias\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.0.conv2.weight, new_key: layer2.0.conv2.conv.weight\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.1.conv2.bias, new_key: layer2.1.conv2.conv.bias\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.1.conv2.weight, new_key: layer2.1.conv2.conv.weight\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.2.conv2.bias, new_key: layer2.2.conv2.conv.bias\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.2.conv2.weight, new_key: layer2.2.conv2.conv.weight\n","2023-02-11 14:43:51,103 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.3.conv2.bias, new_key: layer2.3.conv2.conv.bias\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer2.*conv2.*, old_key: layer2.3.conv2.weight, new_key: layer2.3.conv2.conv.weight\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.0.conv2.bias, new_key: layer3.0.conv2.conv.bias\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.0.conv2.weight, new_key: layer3.0.conv2.conv.weight\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.1.conv2.bias, new_key: layer3.1.conv2.conv.bias\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.1.conv2.weight, new_key: layer3.1.conv2.conv.weight\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.2.conv2.bias, new_key: layer3.2.conv2.conv.bias\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.2.conv2.weight, new_key: layer3.2.conv2.conv.weight\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.3.conv2.bias, new_key: layer3.3.conv2.conv.bias\n","2023-02-11 14:43:51,104 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.3.conv2.weight, new_key: layer3.3.conv2.conv.weight\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.4.conv2.bias, new_key: layer3.4.conv2.conv.bias\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.4.conv2.weight, new_key: layer3.4.conv2.conv.weight\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.5.conv2.bias, new_key: layer3.5.conv2.conv.bias\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer3.*conv2.*, old_key: layer3.5.conv2.weight, new_key: layer3.5.conv2.conv.weight\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.0.conv2.bias, new_key: layer4.0.conv2.conv.bias\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.0.conv2.weight, new_key: layer4.0.conv2.conv.weight\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.1.conv2.bias, new_key: layer4.1.conv2.conv.bias\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.1.conv2.weight, new_key: layer4.1.conv2.conv.weight\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.2.conv2.bias, new_key: layer4.2.conv2.conv.bias\n","2023-02-11 14:43:51,105 stft_core.utils.c2_model_loading INFO: pattern: .*layer4.*conv2.*, old_key: layer4.2.conv2.weight, new_key: layer4.2.conv2.conv.weight\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.bias                                loaded from layer1.0.bn1.bias            of shape (64,)\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn1.weight                              loaded from layer1.0.bn1.weight          of shape (64,)\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.bias                                loaded from layer1.0.bn2.bias            of shape (64,)\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn2.weight                              loaded from layer1.0.bn2.weight          of shape (64,)\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.bias                                loaded from layer1.0.bn3.bias            of shape (256,)\n","2023-02-11 14:43:51,120 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.bn3.weight                              loaded from layer1.0.bn3.weight          of shape (256,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv1.weight                            loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv2.weight                            loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.conv3.weight                            loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.0.weight                     loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.bias                       loaded from layer1.0.downsample.1.bias   of shape (256,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.0.downsample.1.weight                     loaded from layer1.0.downsample.1.weight of shape (256,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.bias                                loaded from layer1.1.bn1.bias            of shape (64,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn1.weight                              loaded from layer1.1.bn1.weight          of shape (64,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.bias                                loaded from layer1.1.bn2.bias            of shape (64,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn2.weight                              loaded from layer1.1.bn2.weight          of shape (64,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.bias                                loaded from layer1.1.bn3.bias            of shape (256,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.bn3.weight                              loaded from layer1.1.bn3.weight          of shape (256,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv1.weight                            loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv2.weight                            loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.1.conv3.weight                            loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.bias                                loaded from layer1.2.bn1.bias            of shape (64,)\n","2023-02-11 14:43:51,121 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn1.weight                              loaded from layer1.2.bn1.weight          of shape (64,)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.bias                                loaded from layer1.2.bn2.bias            of shape (64,)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn2.weight                              loaded from layer1.2.bn2.weight          of shape (64,)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.bias                                loaded from layer1.2.bn3.bias            of shape (256,)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.bn3.weight                              loaded from layer1.2.bn3.weight          of shape (256,)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv1.weight                            loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)\n","2023-02-11 14:43:51,122 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv2.weight                            loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)\n","2023-02-11 14:43:51,196 stft_core.utils.model_serialization INFO: backbone.body.layer1.2.conv3.weight                            loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)\n","2023-02-11 14:43:51,196 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.bias                                loaded from layer2.0.bn1.bias            of shape (128,)\n","2023-02-11 14:43:51,196 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn1.weight                              loaded from layer2.0.bn1.weight          of shape (128,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.bias                                loaded from layer2.0.bn2.bias            of shape (128,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn2.weight                              loaded from layer2.0.bn2.weight          of shape (128,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.bias                                loaded from layer2.0.bn3.bias            of shape (512,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.bn3.weight                              loaded from layer2.0.bn3.weight          of shape (512,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv1.weight                            loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv2.conv.weight                       loaded from layer2.0.conv2.conv.weight   of shape (128, 128, 3, 3)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.conv3.weight                            loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.0.weight                     loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.bias                       loaded from layer2.0.downsample.1.bias   of shape (512,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.0.downsample.1.weight                     loaded from layer2.0.downsample.1.weight of shape (512,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.bias                                loaded from layer2.1.bn1.bias            of shape (128,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn1.weight                              loaded from layer2.1.bn1.weight          of shape (128,)\n","2023-02-11 14:43:51,197 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.bias                                loaded from layer2.1.bn2.bias            of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn2.weight                              loaded from layer2.1.bn2.weight          of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.bias                                loaded from layer2.1.bn3.bias            of shape (512,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.bn3.weight                              loaded from layer2.1.bn3.weight          of shape (512,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv1.weight                            loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv2.conv.weight                       loaded from layer2.1.conv2.conv.weight   of shape (128, 128, 3, 3)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.1.conv3.weight                            loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.bias                                loaded from layer2.2.bn1.bias            of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn1.weight                              loaded from layer2.2.bn1.weight          of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.bias                                loaded from layer2.2.bn2.bias            of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn2.weight                              loaded from layer2.2.bn2.weight          of shape (128,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.bias                                loaded from layer2.2.bn3.bias            of shape (512,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.bn3.weight                              loaded from layer2.2.bn3.weight          of shape (512,)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv1.weight                            loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)\n","2023-02-11 14:43:51,198 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv2.conv.weight                       loaded from layer2.2.conv2.conv.weight   of shape (128, 128, 3, 3)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.2.conv3.weight                            loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.bias                                loaded from layer2.3.bn1.bias            of shape (128,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn1.weight                              loaded from layer2.3.bn1.weight          of shape (128,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.bias                                loaded from layer2.3.bn2.bias            of shape (128,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn2.weight                              loaded from layer2.3.bn2.weight          of shape (128,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.bias                                loaded from layer2.3.bn3.bias            of shape (512,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.bn3.weight                              loaded from layer2.3.bn3.weight          of shape (512,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv1.weight                            loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv2.conv.weight                       loaded from layer2.3.conv2.conv.weight   of shape (128, 128, 3, 3)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer2.3.conv3.weight                            loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.bias                                loaded from layer3.0.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn1.weight                              loaded from layer3.0.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.bias                                loaded from layer3.0.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn2.weight                              loaded from layer3.0.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.bias                                loaded from layer3.0.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,199 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.bn3.weight                              loaded from layer3.0.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv1.weight                            loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv2.conv.weight                       loaded from layer3.0.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.conv3.weight                            loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.0.weight                     loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.bias                       loaded from layer3.0.downsample.1.bias   of shape (1024,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.0.downsample.1.weight                     loaded from layer3.0.downsample.1.weight of shape (1024,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.bias                                loaded from layer3.1.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn1.weight                              loaded from layer3.1.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.bias                                loaded from layer3.1.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn2.weight                              loaded from layer3.1.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.bias                                loaded from layer3.1.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.bn3.weight                              loaded from layer3.1.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,200 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv1.weight                            loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv2.conv.weight                       loaded from layer3.1.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.1.conv3.weight                            loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.bias                                loaded from layer3.2.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn1.weight                              loaded from layer3.2.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.bias                                loaded from layer3.2.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn2.weight                              loaded from layer3.2.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.bias                                loaded from layer3.2.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.bn3.weight                              loaded from layer3.2.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv1.weight                            loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv2.conv.weight                       loaded from layer3.2.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.2.conv3.weight                            loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.bias                                loaded from layer3.3.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn1.weight                              loaded from layer3.3.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.bias                                loaded from layer3.3.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn2.weight                              loaded from layer3.3.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.bias                                loaded from layer3.3.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.bn3.weight                              loaded from layer3.3.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,201 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv1.weight                            loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv2.conv.weight                       loaded from layer3.3.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.3.conv3.weight                            loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.bias                                loaded from layer3.4.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn1.weight                              loaded from layer3.4.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.bias                                loaded from layer3.4.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn2.weight                              loaded from layer3.4.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.bias                                loaded from layer3.4.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.bn3.weight                              loaded from layer3.4.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv1.weight                            loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv2.conv.weight                       loaded from layer3.4.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,202 stft_core.utils.model_serialization INFO: backbone.body.layer3.4.conv3.weight                            loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,297 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.bias                                loaded from layer3.5.bn1.bias            of shape (256,)\n","2023-02-11 14:43:51,297 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn1.weight                              loaded from layer3.5.bn1.weight          of shape (256,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.bias                                loaded from layer3.5.bn2.bias            of shape (256,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn2.weight                              loaded from layer3.5.bn2.weight          of shape (256,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.bias                                loaded from layer3.5.bn3.bias            of shape (1024,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.bn3.weight                              loaded from layer3.5.bn3.weight          of shape (1024,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv1.weight                            loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv2.conv.weight                       loaded from layer3.5.conv2.conv.weight   of shape (256, 256, 3, 3)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer3.5.conv3.weight                            loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.bias                                loaded from layer4.0.bn1.bias            of shape (512,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn1.weight                              loaded from layer4.0.bn1.weight          of shape (512,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.bias                                loaded from layer4.0.bn2.bias            of shape (512,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn2.weight                              loaded from layer4.0.bn2.weight          of shape (512,)\n","2023-02-11 14:43:51,298 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.bias                                loaded from layer4.0.bn3.bias            of shape (2048,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.bn3.weight                              loaded from layer4.0.bn3.weight          of shape (2048,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv1.weight                            loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv2.conv.weight                       loaded from layer4.0.conv2.conv.weight   of shape (512, 512, 3, 3)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.conv3.weight                            loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.0.weight                     loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.bias                       loaded from layer4.0.downsample.1.bias   of shape (2048,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.0.downsample.1.weight                     loaded from layer4.0.downsample.1.weight of shape (2048,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.bias                                loaded from layer4.1.bn1.bias            of shape (512,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn1.weight                              loaded from layer4.1.bn1.weight          of shape (512,)\n","2023-02-11 14:43:51,299 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.bias                                loaded from layer4.1.bn2.bias            of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn2.weight                              loaded from layer4.1.bn2.weight          of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.bias                                loaded from layer4.1.bn3.bias            of shape (2048,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.bn3.weight                              loaded from layer4.1.bn3.weight          of shape (2048,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv1.weight                            loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv2.conv.weight                       loaded from layer4.1.conv2.conv.weight   of shape (512, 512, 3, 3)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.1.conv3.weight                            loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.bias                                loaded from layer4.2.bn1.bias            of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn1.weight                              loaded from layer4.2.bn1.weight          of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.bias                                loaded from layer4.2.bn2.bias            of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn2.weight                              loaded from layer4.2.bn2.weight          of shape (512,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.bias                                loaded from layer4.2.bn3.bias            of shape (2048,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.bn3.weight                              loaded from layer4.2.bn3.weight          of shape (2048,)\n","2023-02-11 14:43:51,300 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv1.weight                            loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)\n","2023-02-11 14:43:51,301 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv2.conv.weight                       loaded from layer4.2.conv2.conv.weight   of shape (512, 512, 3, 3)\n","2023-02-11 14:43:51,301 stft_core.utils.model_serialization INFO: backbone.body.layer4.2.conv3.weight                            loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)\n","2023-02-11 14:43:51,301 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.bias                                    loaded from bn1.bias                     of shape (64,)\n","2023-02-11 14:43:51,301 stft_core.utils.model_serialization INFO: backbone.body.stem.bn1.weight                                  loaded from bn1.weight                   of shape (64,)\n","2023-02-11 14:43:51,302 stft_core.utils.model_serialization INFO: backbone.body.stem.conv1.weight                                loaded from conv1.weight                 of shape (64, 3, 7, 7)\n","2023-02-11 14:43:51,359 stft_core INFO: \n","arguments:\n","{'iteration': 0}\n","build.py dataset_list:  ('ASUVideo_train_videos',)\n","ASUVideo_train_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_train_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_train_videos.txt'}}\n","Had filtered 0 images\n","Had filtered 259 images\n","Saving ASUVideo's keep information into datasets/cache/ASUVideo_train_videos_keep.pkl\n","Had processed 0 images\n","Had processed 189 images\n","Saving ASUVideo's annotation information into datasets/cache/ASUVideo_train_videos_anno.pkl\n","Loaded  Training  set : datasets/ASUVideo/Annotations , number samples: 189\n","2023-02-11 14:43:51,395 stft_core.utils.miscellaneous WARNING: Dataset [CVCVIDSTFTDataset] has no categories attribute, labels.json file won't be created\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c0054b80>\n","2023-02-11 14:43:51,396 stft_core.trainer INFO: Start training\n","2023-02-11 14:43:51,397 stft_core.trainer INFO: iou_types:('bbox',)\n","\n","2023-02-11 14:44:15,821 stft_core.trainer INFO: eta: 2:01:41  iter: 20  loss: 7.8679 (8.3230)  loss_cls: 1.2715 (1.2777)  loss_reg: 0.9568 (0.9446)  loss_centerness: 0.6079 (0.6096)  loss_stft_cls: 0.6841 (0.7040)  loss_stft_reg: 4.4297 (4.7870)  time: 1.1562 (1.2210)  data: 0.0028 (0.0393)  lr: 0.000180  max mem: 4068\n","2023-02-11 14:44:40,006 stft_core.trainer INFO: eta: 2:00:42  iter: 40  loss: 5.6843 (7.1089)  loss_cls: 0.6667 (0.9980)  loss_reg: 0.5172 (0.7502)  loss_centerness: 0.5926 (0.6048)  loss_stft_cls: 0.4108 (0.5668)  loss_stft_reg: 3.5065 (4.1891)  time: 1.2009 (1.2152)  data: 0.0029 (0.0213)  lr: 0.000193  max mem: 4068\n","2023-02-11 14:45:04,587 stft_core.trainer INFO: eta: 2:00:45  iter: 60  loss: 5.5805 (6.6793)  loss_cls: 0.6894 (0.8957)  loss_reg: 0.4424 (0.6536)  loss_centerness: 0.6184 (0.6109)  loss_stft_cls: 0.3424 (0.4920)  loss_stft_reg: 3.5784 (4.0270)  time: 1.2319 (1.2198)  data: 0.0028 (0.0156)  lr: 0.000207  max mem: 4068\n","2023-02-11 14:45:28,585 stft_core.trainer INFO: eta: 1:59:51  iter: 80  loss: 5.5530 (6.3994)  loss_cls: 0.8324 (0.8899)  loss_reg: 0.3889 (0.5860)  loss_centerness: 0.6025 (0.6091)  loss_stft_cls: 0.3043 (0.4472)  loss_stft_reg: 3.3822 (3.8673)  time: 1.1965 (1.2148)  data: 0.0029 (0.0125)  lr: 0.000220  max mem: 4068\n","2023-02-11 14:45:52,577 stft_core.trainer INFO: eta: 1:59:09  iter: 100  loss: 5.0072 (6.1856)  loss_cls: 0.7869 (0.8886)  loss_reg: 0.3522 (0.5478)  loss_centerness: 0.6060 (0.6088)  loss_stft_cls: 0.3204 (0.4231)  loss_stft_reg: 2.9278 (3.7173)  time: 1.1955 (1.2118)  data: 0.0029 (0.0106)  lr: 0.000233  max mem: 4068\n","2023-02-11 14:46:16,647 stft_core.trainer INFO: eta: 1:58:37  iter: 120  loss: 4.4315 (5.9338)  loss_cls: 0.6261 (0.8454)  loss_reg: 0.3256 (0.5131)  loss_centerness: 0.6052 (0.6087)  loss_stft_cls: 0.2875 (0.4019)  loss_stft_reg: 2.6220 (3.5648)  time: 1.1983 (1.2104)  data: 0.0028 (0.0093)  lr: 0.000247  max mem: 4068\n","2023-02-11 14:46:22,728 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000125.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c0364490>\n","2023-02-11 14:46:23,744 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n","100% 259/259 [02:53<00:00,  1.50it/s]\n","2023-02-11 14:49:16,868 stft_core.inference INFO: Total run time: 0:02:53.123723 (0.6684313639710768 s / img per device, on 1 devices)\n","2023-02-11 14:49:16,868 stft_core.inference INFO: Model inference time: 0:02:51.731566 (0.6630562391980734 s / img per device, on 1 devices)\n","2023-02-11 14:49:16,869 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 14:49:16,935 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 14:49:16,939 stft_core.inference INFO: \n","score_thr:0.60  Precision: 77.6119   Recall: 27.5132   Accuracy: 41.3127   Sepcificity: 78.5714   F1_score: 40.6250   F2_score: 31.5917 \n","2023-02-11 14:49:16,939 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 14:49:16,944 stft_core.inference INFO: \n","score_thr:0.60  Precision: 92.8571   Recall: 27.5132   F1_score: 42.4490   F2_score: 32.0197 \n","2023-02-11 14:49:35,007 stft_core.trainer INFO: eta: 3:59:42  iter: 140  loss: 4.4361 (5.7753)  loss_cls: 0.7474 (0.8421)  loss_reg: 0.3925 (0.4999)  loss_centerness: 0.6160 (0.6106)  loss_stft_cls: 0.2622 (0.3856)  loss_stft_reg: 2.2804 (3.4371)  time: 1.2149 (2.4543)  data: 0.0030 (1.2529)  lr: 0.000260  max mem: 4559\n","2023-02-11 14:49:59,164 stft_core.trainer INFO: eta: 3:43:43  iter: 160  loss: 5.9068 (5.7689)  loss_cls: 1.8702 (0.9568)  loss_reg: 0.3440 (0.4819)  loss_centerness: 0.6012 (0.6106)  loss_stft_cls: 0.3552 (0.3856)  loss_stft_reg: 2.4668 (3.3340)  time: 1.2039 (2.2985)  data: 0.0030 (1.0967)  lr: 0.000273  max mem: 4559\n","2023-02-11 14:50:23,357 stft_core.trainer INFO: eta: 3:31:13  iter: 180  loss: 4.3823 (5.6423)  loss_cls: 0.5596 (0.9130)  loss_reg: 0.4069 (0.4727)  loss_centerness: 0.6136 (0.6112)  loss_stft_cls: 0.2437 (0.3707)  loss_stft_reg: 2.4577 (3.2747)  time: 1.2083 (2.1775)  data: 0.0029 (0.9752)  lr: 0.000287  max mem: 4559\n","2023-02-11 14:50:47,632 stft_core.trainer INFO: eta: 3:21:10  iter: 200  loss: 4.0846 (5.5064)  loss_cls: 0.3767 (0.8691)  loss_reg: 0.3525 (0.4626)  loss_centerness: 0.5934 (0.6103)  loss_stft_cls: 0.1984 (0.3586)  loss_stft_reg: 2.2273 (3.2059)  time: 1.2091 (2.0812)  data: 0.0030 (0.8780)  lr: 0.000300  max mem: 4559\n","2023-02-11 14:51:11,837 stft_core.trainer INFO: eta: 3:12:51  iter: 220  loss: 3.2280 (5.3214)  loss_cls: 0.3478 (0.8298)  loss_reg: 0.3514 (0.4529)  loss_centerness: 0.6041 (0.6104)  loss_stft_cls: 0.1650 (0.3435)  loss_stft_reg: 1.6965 (3.0849)  time: 1.2079 (2.0020)  data: 0.0028 (0.7985)  lr: 0.000313  max mem: 4559\n","2023-02-11 14:51:36,050 stft_core.trainer INFO: eta: 3:05:51  iter: 240  loss: 4.8050 (5.2937)  loss_cls: 1.3729 (0.8726)  loss_reg: 0.3584 (0.4455)  loss_centerness: 0.6113 (0.6101)  loss_stft_cls: 0.2274 (0.3362)  loss_stft_reg: 2.0410 (3.0294)  time: 1.2084 (1.9360)  data: 0.0029 (0.7322)  lr: 0.000327  max mem: 4559\n","2023-02-11 14:51:48,193 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000250.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c03f5130>\n","2023-02-11 14:51:49,198 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n","100% 259/259 [02:54<00:00,  1.48it/s]\n","2023-02-11 14:54:43,856 stft_core.inference INFO: Total run time: 0:02:54.657732 (0.674354177644354 s / img per device, on 1 devices)\n","2023-02-11 14:54:43,857 stft_core.inference INFO: Model inference time: 0:02:53.346589 (0.6692918506828515 s / img per device, on 1 devices)\n","2023-02-11 14:54:43,857 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 14:54:43,922 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 14:54:43,926 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 84.1270   Accuracy: 88.4170   Sepcificity: 100.0000   F1_score: 91.3793   F2_score: 86.8852 \n","2023-02-11 14:54:43,926 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 14:54:43,936 stft_core.inference INFO: \n","score_thr:0.60  Precision: 99.3711   Recall: 83.5979   F1_score: 90.8046   F2_score: 86.3388 \n","2023-02-11 14:54:55,966 stft_core.trainer INFO: eta: 4:04:31  iter: 260  loss: 3.4778 (5.1788)  loss_cls: 0.4720 (0.8450)  loss_reg: 0.4207 (0.4442)  loss_centerness: 0.6157 (0.6108)  loss_stft_cls: 0.2033 (0.3298)  loss_stft_reg: 1.7062 (2.9490)  time: 1.2105 (2.5560)  data: 0.0029 (1.3521)  lr: 0.000340  max mem: 4562\n","2023-02-11 14:55:20,123 stft_core.trainer INFO: eta: 3:54:29  iter: 280  loss: 3.4110 (5.0812)  loss_cls: 0.3669 (0.8149)  loss_reg: 0.3209 (0.4375)  loss_centerness: 0.6252 (0.6127)  loss_stft_cls: 0.2340 (0.3272)  loss_stft_reg: 1.7224 (2.8889)  time: 1.2053 (2.4597)  data: 0.0030 (1.2557)  lr: 0.000353  max mem: 4562\n","2023-02-11 14:55:44,315 stft_core.trainer INFO: eta: 3:45:45  iter: 300  loss: 3.1662 (4.9610)  loss_cls: 0.3840 (0.7918)  loss_reg: 0.3228 (0.4297)  loss_centerness: 0.6098 (0.6128)  loss_stft_cls: 0.1333 (0.3164)  loss_stft_reg: 1.5963 (2.8103)  time: 1.2067 (2.3764)  data: 0.0029 (1.1722)  lr: 0.000367  max mem: 4562\n","2023-02-11 14:56:08,550 stft_core.trainer INFO: eta: 3:38:04  iter: 320  loss: 2.9707 (4.8647)  loss_cls: 0.3432 (0.7701)  loss_reg: 0.2992 (0.4231)  loss_centerness: 0.5972 (0.6122)  loss_stft_cls: 0.1325 (0.3059)  loss_stft_reg: 1.6513 (2.7536)  time: 1.2117 (2.3036)  data: 0.0031 (1.0991)  lr: 0.000380  max mem: 4562\n","2023-02-11 14:56:32,718 stft_core.trainer INFO: eta: 3:31:13  iter: 340  loss: 3.4739 (4.7966)  loss_cls: 0.5269 (0.7583)  loss_reg: 0.3111 (0.4188)  loss_centerness: 0.6086 (0.6119)  loss_stft_cls: 0.1309 (0.2982)  loss_stft_reg: 1.9105 (2.7094)  time: 1.2067 (2.2392)  data: 0.0028 (1.0347)  lr: 0.000393  max mem: 4562\n","2023-02-11 14:56:56,903 stft_core.trainer INFO: eta: 3:25:06  iter: 360  loss: 3.5787 (4.7420)  loss_cls: 0.4145 (0.7435)  loss_reg: 0.4153 (0.4191)  loss_centerness: 0.6214 (0.6125)  loss_stft_cls: 0.1702 (0.2921)  loss_stft_reg: 1.8330 (2.6747)  time: 1.2045 (2.1820)  data: 0.0029 (0.9774)  lr: 0.000407  max mem: 4562\n","2023-02-11 14:57:14,996 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000375.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87a37e42b0>\n","2023-02-11 14:57:16,002 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n","100% 259/259 [02:54<00:00,  1.48it/s]\n","2023-02-11 15:00:10,581 stft_core.inference INFO: Total run time: 0:02:54.578343 (0.6740476560408545 s / img per device, on 1 devices)\n","2023-02-11 15:00:10,581 stft_core.inference INFO: Model inference time: 0:02:53.151936 (0.6685402918046045 s / img per device, on 1 devices)\n","2023-02-11 15:00:10,581 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 15:00:10,803 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 15:00:10,810 stft_core.inference INFO: \n","score_thr:0.60  Precision: 97.3404   Recall: 96.8254   Accuracy: 95.7529   Sepcificity: 92.8571   F1_score: 97.0822   F2_score: 96.9280 \n","2023-02-11 15:00:10,810 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 15:00:10,832 stft_core.inference INFO: \n","score_thr:0.60  Precision: 94.7644   Recall: 95.7672   F1_score: 95.2632   F2_score: 95.5649 \n","2023-02-11 15:00:16,827 stft_core.trainer INFO: eta: 4:02:53  iter: 380  loss: 3.4192 (4.6759)  loss_cls: 0.3465 (0.7254)  loss_reg: 0.3205 (0.4150)  loss_centerness: 0.6129 (0.6121)  loss_stft_cls: 0.1060 (0.2838)  loss_stft_reg: 1.8716 (2.6396)  time: 1.2063 (2.5932)  data: 0.0029 (1.3888)  lr: 0.000420  max mem: 4562\n","2023-02-11 15:00:41,204 stft_core.trainer INFO: eta: 3:55:37  iter: 400  loss: 3.0212 (4.6102)  loss_cls: 0.3033 (0.7075)  loss_reg: 0.3369 (0.4112)  loss_centerness: 0.5953 (0.6113)  loss_stft_cls: 0.1295 (0.2772)  loss_stft_reg: 1.6748 (2.6029)  time: 1.2152 (2.5245)  data: 0.0029 (1.3195)  lr: 0.000433  max mem: 4562\n","2023-02-11 15:01:05,511 stft_core.trainer INFO: eta: 3:48:58  iter: 420  loss: 2.5508 (4.5253)  loss_cls: 0.2369 (0.6859)  loss_reg: 0.3069 (0.4079)  loss_centerness: 0.6026 (0.6112)  loss_stft_cls: 0.1075 (0.2688)  loss_stft_reg: 1.4316 (2.5515)  time: 1.2149 (2.4622)  data: 0.0029 (1.2569)  lr: 0.000447  max mem: 4562\n","2023-02-11 15:01:29,765 stft_core.trainer INFO: eta: 3:42:53  iter: 440  loss: 3.2083 (4.4665)  loss_cls: 0.2998 (0.6698)  loss_reg: 0.3327 (0.4049)  loss_centerness: 0.6132 (0.6114)  loss_stft_cls: 0.1216 (0.2628)  loss_stft_reg: 1.8561 (2.5176)  time: 1.2092 (2.4054)  data: 0.0032 (1.1999)  lr: 0.000460  max mem: 4562\n","2023-02-11 15:01:53,899 stft_core.trainer INFO: eta: 3:37:17  iter: 460  loss: 3.0185 (4.4208)  loss_cls: 0.3194 (0.6568)  loss_reg: 0.3794 (0.4039)  loss_centerness: 0.6192 (0.6118)  loss_stft_cls: 0.0946 (0.2575)  loss_stft_reg: 1.5451 (2.4908)  time: 1.2015 (2.3533)  data: 0.0030 (1.1478)  lr: 0.000473  max mem: 4562\n","2023-02-11 15:02:18,163 stft_core.trainer INFO: eta: 3:32:07  iter: 480  loss: 2.7652 (4.3553)  loss_cls: 0.2656 (0.6419)  loss_reg: 0.3194 (0.4010)  loss_centerness: 0.6040 (0.6114)  loss_stft_cls: 0.0828 (0.2509)  loss_stft_reg: 1.4486 (2.4501)  time: 1.2119 (2.3058)  data: 0.0029 (1.1002)  lr: 0.000487  max mem: 4562\n","2023-02-11 15:02:42,343 stft_core.trainer INFO: eta: 3:27:20  iter: 500  loss: 2.7990 (4.3073)  loss_cls: 0.2772 (0.6286)  loss_reg: 0.3056 (0.3980)  loss_centerness: 0.5988 (0.6112)  loss_stft_cls: 0.0735 (0.2460)  loss_stft_reg: 1.5337 (2.4236)  time: 1.2035 (2.2619)  data: 0.0029 (1.0563)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:02:42,347 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000500.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c040a4f0>\n","2023-02-11 15:02:43,383 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n","100% 259/259 [02:55<00:00,  1.48it/s]\n","2023-02-11 15:05:38,752 stft_core.inference INFO: Total run time: 0:02:55.368493 (0.6770984279603112 s / img per device, on 1 devices)\n","2023-02-11 15:05:38,752 stft_core.inference INFO: Model inference time: 0:02:53.813515 (0.6710946523084603 s / img per device, on 1 devices)\n","2023-02-11 15:05:38,752 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 15:05:38,818 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 15:05:38,822 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 12.6984   Accuracy: 36.2934   Sepcificity: 100.0000   F1_score: 22.5352   F2_score: 15.3846 \n","2023-02-11 15:05:38,822 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 15:05:38,826 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 12.6984   F1_score: 22.5352   F2_score: 15.3846 \n","2023-02-11 15:06:03,043 stft_core.trainer INFO: eta: 3:53:53  iter: 520  loss: 2.6184 (4.2509)  loss_cls: 0.2464 (0.6156)  loss_reg: 0.2939 (0.3949)  loss_centerness: 0.6030 (0.6111)  loss_stft_cls: 0.0811 (0.2403)  loss_stft_reg: 1.3446 (2.3891)  time: 1.2118 (2.5609)  data: 0.0028 (1.3552)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:06:27,308 stft_core.trainer INFO: eta: 3:48:29  iter: 540  loss: 2.4316 (4.1938)  loss_cls: 0.2583 (0.6048)  loss_reg: 0.2522 (0.3904)  loss_centerness: 0.6005 (0.6106)  loss_stft_cls: 0.0889 (0.2350)  loss_stft_reg: 1.3359 (2.3530)  time: 1.2105 (2.5109)  data: 0.0028 (1.3051)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:06:51,576 stft_core.trainer INFO: eta: 3:43:27  iter: 560  loss: 2.5139 (4.1481)  loss_cls: 0.2182 (0.5928)  loss_reg: 0.2829 (0.3875)  loss_centerness: 0.6102 (0.6105)  loss_stft_cls: 0.0897 (0.2315)  loss_stft_reg: 1.2656 (2.3259)  time: 1.2103 (2.4646)  data: 0.0030 (1.2586)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:07:15,779 stft_core.trainer INFO: eta: 3:38:43  iter: 580  loss: 2.0530 (4.0812)  loss_cls: 0.1989 (0.5791)  loss_reg: 0.2604 (0.3834)  loss_centerness: 0.5954 (0.6102)  loss_stft_cls: 0.0612 (0.2260)  loss_stft_reg: 0.9304 (2.2825)  time: 1.2065 (2.4213)  data: 0.0027 (1.2153)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:07:40,023 stft_core.trainer INFO: eta: 3:34:17  iter: 600  loss: 2.3714 (4.0341)  loss_cls: 0.2370 (0.5693)  loss_reg: 0.2397 (0.3795)  loss_centerness: 0.5906 (0.6098)  loss_stft_cls: 0.0717 (0.2217)  loss_stft_reg: 1.2116 (2.2538)  time: 1.2096 (2.3810)  data: 0.0029 (1.1749)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:08:04,305 stft_core.trainer INFO: eta: 3:30:07  iter: 620  loss: 2.4220 (3.9927)  loss_cls: 0.2463 (0.5597)  loss_reg: 0.2342 (0.3763)  loss_centerness: 0.5845 (0.6094)  loss_stft_cls: 0.0704 (0.2176)  loss_stft_reg: 1.3198 (2.2296)  time: 1.2113 (2.3434)  data: 0.0029 (1.1371)  lr: 0.000500  max mem: 4562\n","2023-02-11 15:08:10,367 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000625.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c035b100>\n","2023-02-11 15:08:11,369 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n","100% 259/259 [02:55<00:00,  1.48it/s]\n","2023-02-11 15:11:06,595 stft_core.inference INFO: Total run time: 0:02:55.225687 (0.6765470532376794 s / img per device, on 1 devices)\n","2023-02-11 15:11:06,595 stft_core.inference INFO: Model inference time: 0:02:53.952003 (0.6716293570617912 s / img per device, on 1 devices)\n","2023-02-11 15:11:06,596 stft_core.inference INFO:  performing cvcvideo evaluation.\n","2023-02-11 15:11:06,693 stft_core.inference INFO:  Polyp Detection Task:\n","2023-02-11 15:11:06,699 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 93.6508   Accuracy: 95.3668   Sepcificity: 100.0000   F1_score: 96.7213   F2_score: 94.8553 \n","2023-02-11 15:11:06,699 stft_core.inference INFO:  Polyp Localization Task:\n","2023-02-11 15:11:06,715 stft_core.inference INFO: \n","score_thr:0.60  Precision: 100.0000   Recall: 93.6508   F1_score: 96.7213   F2_score: 94.8553 \n","2023-02-11 15:11:24,905 stft_core.trainer INFO: eta: 3:50:48  iter: 640  loss: 2.3823 (3.9472)  loss_cls: 0.1867 (0.5491)  loss_reg: 0.2598 (0.3727)  loss_centerness: 0.5950 (0.6092)  loss_stft_cls: 0.0597 (0.2136)  loss_stft_reg: 1.2228 (2.2025)  time: 1.2119 (2.5836)  data: 0.0030 (1.3772)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:11:49,204 stft_core.trainer INFO: eta: 3:46:14  iter: 660  loss: 2.5424 (3.9088)  loss_cls: 0.1871 (0.5396)  loss_reg: 0.2666 (0.3704)  loss_centerness: 0.5918 (0.6088)  loss_stft_cls: 0.0633 (0.2096)  loss_stft_reg: 1.3747 (2.1803)  time: 1.2125 (2.5421)  data: 0.0028 (1.3356)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:12:13,574 stft_core.trainer INFO: eta: 3:41:57  iter: 680  loss: 2.2473 (3.8711)  loss_cls: 0.1717 (0.5307)  loss_reg: 0.2659 (0.3681)  loss_centerness: 0.5906 (0.6084)  loss_stft_cls: 0.0722 (0.2066)  loss_stft_reg: 1.0654 (2.1573)  time: 1.2165 (2.5032)  data: 0.0029 (1.2964)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:12:37,827 stft_core.trainer INFO: eta: 3:37:51  iter: 700  loss: 2.3870 (3.8405)  loss_cls: 0.2276 (0.5240)  loss_reg: 0.2727 (0.3659)  loss_centerness: 0.6018 (0.6081)  loss_stft_cls: 0.0633 (0.2035)  loss_stft_reg: 1.0615 (2.1390)  time: 1.2113 (2.4663)  data: 0.0028 (1.2594)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:13:02,175 stft_core.trainer INFO: eta: 3:33:59  iter: 720  loss: 2.3794 (3.8064)  loss_cls: 0.2794 (0.5173)  loss_reg: 0.2551 (0.3638)  loss_centerness: 0.6015 (0.6081)  loss_stft_cls: 0.1003 (0.2010)  loss_stft_reg: 1.1142 (2.1162)  time: 1.2121 (2.4316)  data: 0.0030 (1.2245)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:13:26,422 stft_core.trainer INFO: eta: 3:30:17  iter: 740  loss: 2.3632 (3.7721)  loss_cls: 0.2900 (0.5115)  loss_reg: 0.2923 (0.3621)  loss_centerness: 0.5912 (0.6077)  loss_stft_cls: 0.0844 (0.1983)  loss_stft_reg: 1.1606 (2.0926)  time: 1.2077 (2.3987)  data: 0.0027 (1.1915)  lr: 0.000500  max mem: 4563\n","2023-02-11 15:13:38,472 stft_core.utils.checkpoint INFO: Saving checkpoint to log_dir/asuvid_R_50_STFT/model_0000750.pth\n","build.py dataset_list:  ('ASUVideo_val_videos',)\n","ASUVideo_val_videos\n","<class 'stft_core.config.paths_catalog.DatasetCatalog'>\n","{'factory': 'CVCVIDSTFTDataset', 'args': {'image_set': 'ASUVideo_val_videos', 'data_dir': 'datasets', 'img_dir': 'datasets/ASUVideo/Data', 'anno_path': 'datasets/ASUVideo/Annotations', 'img_index': 'datasets/ASUVideo/ImageSets/ASUVideo_val_videos.txt'}}\n","ASUVideo's annotation information loaded from datasets/cache/ASUVideo_val_videos_anno.pkl\n","Loaded  Validation  set : datasets/ASUVideo/Annotations , number samples: 259\n","build.py dataset:  <stft_core.data.datasets.cvcvid_stft.CVCVIDSTFTDataset object at 0x7f87c02e1d60>\n","2023-02-11 15:13:39,546 stft_core.inference INFO: Start evaluation on [Validation] dataset(259 images).\n"," 49% 128/259 [01:27<01:26,  1.51it/s]Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/subprocess.py\", line 1083, in wait\n","    return self._wait(timeout=timeout)\n","  File \"/usr/lib/python3.8/subprocess.py\", line 1806, in _wait\n","    (pid, sts) = self._try_wait(0)\n","  File \"/usr/lib/python3.8/subprocess.py\", line 1764, in _try_wait\n","    (pid, sts) = os.waitpid(self.pid, wait_flags)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 263, in <module>\n","    main()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 256, in main\n","    process.wait()\n","  File \"/usr/lib/python3.8/subprocess.py\", line 1096, in wait\n","    self._wait(timeout=sigint_timeout)\n","  File \"/usr/lib/python3.8/subprocess.py\", line 1800, in _wait\n","    time.sleep(delay)\n","KeyboardInterrupt\n"," 49% 128/259 [01:28<01:30,  1.45it/s]\n","Traceback (most recent call last):\n","  File \"tools/train_net.py\", line 188, in <module>\n","    main()\n","  File \"tools/train_net.py\", line 183, in main\n","    model = train(cfg, args.local_rank, args.distributed, logger, tb_writer)\n","  File \"tools/train_net.py\", line 88, in train\n","    do_train(\n","  File \"/content/STFT/stft_core/engine/trainer.py\", line 159, in do_train\n","    eval_metric_list = inference(cfg,  # The result can be used for additional logging, e. g. for TensorBoard\n","  File \"/content/STFT/stft_core/engine/inference.py\", line 102, in inference\n","    predictions = compute_on_dataset(model, dataset, data_loader, device, bbox_aug, cfg.MODEL.VID.METHOD, inference_timer)\n","  File \"/content/STFT/stft_core/engine/inference.py\", line 41, in compute_on_dataset\n","    output = model(images)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/STFT/stft_core/modeling/detector/generalized_rcnn_stft.py\", line 60, in forward\n","    return self._forward_test(images[\"cur\"], infos)\n","  File \"/content/STFT/stft_core/modeling/detector/generalized_rcnn_stft.py\", line 118, in _forward_test\n","    proposals, _ = self.rpn(imgs.tensors, sample_features)\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/STFT/stft_core/modeling/rpn/fcos_stft/fcos_stft.py\", line 293, in forward\n","    return self._forward_test(\n","  File \"/content/STFT/stft_core/modeling/rpn/fcos_stft/fcos_stft.py\", line 311, in _forward_test\n","    boxes = self.box_selector_test(\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/STFT/stft_core/modeling/rpn/fcos_stft/inference.py\", line 157, in forward\n","    results_per_image = self.forward_for_single_image(shifts_per_image,\n","  File \"/content/STFT/stft_core/modeling/rpn/fcos_stft/inference.py\", line 72, in forward_for_single_image\n","    stft_bbox_std = stft_based_box[0].new_tensor(self.stft_bbox_std)\n","KeyboardInterrupt\n","^C\n"]}]}]}